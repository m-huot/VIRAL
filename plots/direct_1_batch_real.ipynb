{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a one batch acquisition using the variants/mutations that were found in Gisaid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#import * from utils, gaussian_process, active_learner in ../src\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import *\n",
    "from gaussian_process import *\n",
    "from active_learner import *\n",
    "from hist_al import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get gisaid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>count</th>\n",
       "      <th>q05_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>3980832</td>\n",
       "      <td>2021-06-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1297376</td>\n",
       "      <td>2022-01-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1219498</td>\n",
       "      <td>2022-06-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>1094468</td>\n",
       "      <td>2021-01-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>816046</td>\n",
       "      <td>2020-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25723</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25724</th>\n",
       "      <td>DITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-18 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25725 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     seq    count  \\\n",
       "0      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  3980832   \n",
       "1      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  1297376   \n",
       "2      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  1219498   \n",
       "3      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  1094468   \n",
       "4      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...   816046   \n",
       "...                                                  ...      ...   \n",
       "25720  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25721  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25722  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25723  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25724  DITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...        1   \n",
       "\n",
       "                  q05_date  \n",
       "0      2021-06-29 00:00:00  \n",
       "1      2022-01-31 00:00:00  \n",
       "2      2022-06-11 00:00:00  \n",
       "3      2021-01-18 00:00:00  \n",
       "4      2020-03-26 00:00:00  \n",
       "...                    ...  \n",
       "25720  2023-01-02 00:00:00  \n",
       "25721  2023-01-12 00:00:00  \n",
       "25722  2022-10-19 00:00:00  \n",
       "25723  2022-10-31 00:00:00  \n",
       "25724  2021-02-18 00:00:00  \n",
       "\n",
       "[25725 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbd_df=pd.read_csv('../gisaid/rbd_dates.csv', sep=',')\n",
    "rbd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMS dataset (Bloom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>unique_sequences</th>\n",
       "      <th>unique_mutations</th>\n",
       "      <th>mutations_observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{V367F, A520S, Y453F}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>{S494P, R357K, L452R, N501T, A522S, K417N, S47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>{S494P, D427N, A475V, R346K, S477N, F490S, A52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>86</td>\n",
       "      <td>64</td>\n",
       "      <td>{S494P, D427N, S477I, V382L, N354K, V483F, Q49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>116</td>\n",
       "      <td>77</td>\n",
       "      <td>{P384L, V483F, F490S, L455F, N501T, F490L, N45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>156</td>\n",
       "      <td>91</td>\n",
       "      <td>{P384L, V483F, F490S, L455F, E484R, F486I, N50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date    end_date  unique_sequences  unique_mutations  \\\n",
       "0  2020-01-01  2020-06-30                 4                 3   \n",
       "1  2020-01-01  2020-12-31                15                14   \n",
       "2  2020-01-01  2021-06-30                35                23   \n",
       "3  2020-01-01  2021-12-31                86                64   \n",
       "4  2020-01-01  2022-06-30               116                77   \n",
       "5  2020-01-01  2022-12-31               156                91   \n",
       "\n",
       "                                  mutations_observed  \n",
       "0                              {V367F, A520S, Y453F}  \n",
       "1  {S494P, R357K, L452R, N501T, A522S, K417N, S47...  \n",
       "2  {S494P, D427N, A475V, R346K, S477N, F490S, A52...  \n",
       "3  {S494P, D427N, S477I, V382L, N354K, V483F, Q49...  \n",
       "4  {P384L, V483F, F490S, L455F, N501T, F490L, N45...  \n",
       "5  {P384L, V483F, F490S, L455F, E484R, F486I, N50...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function get_mutation\n",
    "def get_mutation(WT, sequences):\n",
    "    \"\"\"\n",
    "    Function to determine mutations from the WT sequence given a list of sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    - WT (str): The wild-type (reference) sequence.\n",
    "    - sequences (list): List of sequences to analyze for mutations.\n",
    "    \n",
    "    Returns:\n",
    "    - set: A set of mutations, where each mutation is represented as WT+site+mutant.\n",
    "    \"\"\"\n",
    "    mutations = set()\n",
    "    \n",
    "    # Iterate through each sequence in the list\n",
    "    for seq in sequences:\n",
    "        # Ensure sequences are of the same length to allow site-based comparison\n",
    "        if len(seq) != len(WT):\n",
    "            continue\n",
    "        \n",
    "        # Compare each site in the sequence to the WT\n",
    "        for i, (wt_residue, mutant_residue) in enumerate(zip(WT, seq), start=1):\n",
    "            if wt_residue != mutant_residue:\n",
    "                # Format the mutation as WT+site+mutant (e.g., \"A12G\" for a mutation from A to G at position 12)\n",
    "                mutation = f\"{wt_residue}{i+330}{mutant_residue}\"\n",
    "                mutations.add(mutation)\n",
    "                \n",
    "    return mutations\n",
    "\n",
    "# Define WT sequence\n",
    "WT_sequence = \"NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\"\n",
    "\n",
    "# Define date intervals for subsets\n",
    "intervals = [\n",
    "    (\"2020-01-01\", \"2020-06-30\"),\n",
    "    (\"2020-01-01\", \"2020-12-31\"),\n",
    "    (\"2020-01-01\", \"2021-06-30\"),\n",
    "    (\"2020-01-01\", \"2021-12-31\"),\n",
    "    (\"2020-01-01\", \"2022-06-30\"),\n",
    "    (\"2020-01-01\", \"2022-12-31\")\n",
    "]\n",
    "# Initialize list to store detailed results\n",
    "detailed_results = []\n",
    "\n",
    "# Iterate over each date interval, similar to previous analysis\n",
    "for start_date, end_date in intervals:\n",
    "    # Filter by date range\n",
    "    subset = rbd_df[(rbd_df['q05_date'] >= start_date) & (rbd_df['q05_date'] <= end_date)]\n",
    "    subset = subset[subset['count'] >= 1000]\n",
    "    \n",
    "    # Get unique sequences in the subset\n",
    "    unique_sequences = subset['seq'].unique()\n",
    "    \n",
    "    # Calculate mutations using the get_mutation function\n",
    "    mutations = get_mutation(WT_sequence, unique_sequences)\n",
    "    \n",
    "    # Append result for the current subset\n",
    "    detailed_results.append({\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'unique_sequences': len(unique_sequences),\n",
    "        'unique_mutations': len(mutations),\n",
    "        'mutations_observed': mutations\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for easy display\n",
    "detailed_results_df = pd.DataFrame(detailed_results)\n",
    "detailed_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V367F', 'A520S', 'Y453F']\n",
      "['S494P', 'R357K', 'L452R', 'N501T', 'A522S', 'K417N', 'S477N', 'Y453F', 'N439K', 'N501Y', 'V367F', 'E484K', 'A520S', 'N440K']\n",
      "['S494P', 'D427N', 'A475V', 'R346K', 'S477N', 'F490S', 'A520S', 'K417T', 'N501T', 'K417N', 'N501Y', 'V367F', 'T478K', 'R357K', 'Y453F', 'N439K', 'E484K', 'N440K', 'R346S', 'E484Q', 'A522S', 'L452R', 'L452Q']\n",
      "['S494P', 'D427N', 'S477I', 'V382L', 'N354K', 'V483F', 'Q498R', 'R346K', 'S477N', 'P384L', 'F490S', 'L455F', 'A475V', 'E484A', 'A352S', 'K417T', 'A520S', 'S371L', 'T385I', 'G496S', 'N501T', 'F490L', 'K417N', 'P479S', 'N501Y', 'V367F', 'S373P', 'K356R', 'T478K', 'Q493R', 'G446S', 'V367L', 'R357K', 'G476S', 'R346I', 'A344S', 'Y453F', 'N439K', 'Q414R', 'A522V', 'R408I', 'P463S', 'S459F', 'E484K', 'P479L', 'N460S', 'N440K', 'G339D', 'A411S', 'E484Q', 'R346S', 'Q414K', 'A522S', 'L452R', 'L452Q', 'D427V', 'N354T', 'S494L', 'A348S', 'G446V', 'T376I', 'Y505H', 'A419S', 'S375F']\n",
      "['P384L', 'V483F', 'F490S', 'L455F', 'N501T', 'F490L', 'N450D', 'K356R', 'A522P', 'Q493R', 'G446S', 'V367L', 'R357K', 'R408I', 'T376A', 'S371F', 'P479L', 'N440K', 'G339D', 'A522S', 'L452Q', 'D427V', 'T376I', 'D405N', 'A419S', 'D427N', 'V382L', 'N354K', 'Q498R', 'S477N', 'A520S', 'S371L', 'N460K', 'A344S', 'N460S', 'E484Q', 'R408S', 'L452R', 'S494L', 'Y505H', 'G339H', 'S494P', 'R346K', 'A352S', 'K417T', 'V367F', 'L452M', 'G339N', 'Y453F', 'E484K', 'A411S', 'Q414K', 'S371Y', 'N354T', 'A348S', 'R346T', 'S375F', 'S477I', 'A475V', 'E484A', 'T385I', 'G496S', 'K417N', 'P479S', 'N501Y', 'S373P', 'T478K', 'F486V', 'G476S', 'R346I', 'N439K', 'Q414R', 'A522V', 'P463S', 'S459F', 'R346S', 'G446V']\n",
      "['P384L', 'V483F', 'F490S', 'L455F', 'E484R', 'F486I', 'N501T', 'F490L', 'N450D', 'K356R', 'A522P', 'Q493R', 'G446S', 'V367L', 'R357K', 'R408I', 'T376A', 'S371F', 'P479L', 'N440K', 'G339D', 'A522S', 'L452Q', 'D427V', 'T376I', 'V445P', 'D405N', 'A419S', 'D427N', 'V382L', 'N354K', 'Q498R', 'S477N', 'F486S', 'A520S', 'S371L', 'N460K', 'A344S', 'K444R', 'N460S', 'V445A', 'E484Q', 'R408S', 'L452R', 'S494L', 'Y505H', 'G339H', 'L368I', 'S494P', 'R346K', 'A352S', 'K417T', 'F486P', 'K356T', 'V367F', 'K444T', 'L452M', 'G339N', 'Y453F', 'K444N', 'E484K', 'A411S', 'K444M', 'Q414K', 'S371Y', 'N354T', 'A348S', 'R346T', 'F486A', 'S375F', 'S477I', 'A475V', 'G446D', 'E484A', 'T385I', 'G496S', 'K417N', 'P479S', 'N501Y', 'S373P', 'T478K', 'F486V', 'R346I', 'G476S', 'N439K', 'Q414R', 'A522V', 'P463S', 'S459F', 'R346S', 'G446V']\n"
     ]
    }
   ],
   "source": [
    "for index, row in detailed_results_df.iterrows():\n",
    "    print(list(row['mutations_observed']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED = \"esm3_coord\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings of shape torch.Size([3803, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VIRAL\\plots\\../src\\utils.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path)  # Load the tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3122, 5)\n"
     ]
    }
   ],
   "source": [
    "df, train_x, train_y, targets = load_and_preprocess_data(EMBED)\n",
    "pheno_columns = [\n",
    "    \"delta_log_kd_ACE2\",\n",
    "    \"delta_log_kd_LY-CoV016\",\n",
    "    \"delta_log_kd_REGN10987\",\n",
    "    \"delta_log_kd_LY-CoV555\",\n",
    "    \"delta_log_kd_S309\",\n",
    "]\n",
    "pheno = df[pheno_columns]\n",
    "pheno = pheno.to_numpy()\n",
    "print(pheno.shape)\n",
    "\n",
    "fitnesses = bio_model(pheno)\n",
    "train_y = torch.tensor(\n",
    "    np.array([fitnesses, fitnesses, fitnesses, fitnesses, fitnesses]).transpose()\n",
    ")\n",
    "\n",
    "dataset = Dataset_perso(train_x, train_y)\n",
    "site_rbd_list = np.unique(df[\"site_SARS2\"].values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 mutation indexes: [555, 3030, 1956]\n",
      "3\n",
      "Row 1 mutation indexes: [2629, 388, 1946, 2727, 3068, 1411, 2362, 1956, 1713, 2730, 555, 2472, 3030, 1732]\n",
      "14\n",
      "Row 2 mutation indexes: [2629, 1544, 2329, 217, 2362, 2574, 3030, 1416, 2727, 1411, 2730, 555, 2378, 388, 1956, 1713, 2472, 1732, 223, 2477, 3068, 1946, 1945]\n",
      "23\n",
      "Row 3 mutation indexes: [2629, 1544, 2358, 826, 350, 2450, 2668, 217, 2362, 864, 2574, 1975, 2329, 2465, 318, 1416, 3030, 636, 881, 2650, 2727, 2568, 1411, 2403, 2730, 555, 677, 374, 2378, 2611, 1833, 560, 388, 2346, 216, 185, 1956, 1713, 1376, 3070, 1275, 2118, 2032, 2472, 2398, 2061, 1732, 97, 1339, 2477, 223, 1371, 3068, 1946, 1945, 1550, 357, 2626, 261, 1835, 729, 2775, 1453, 707]\n",
      "64\n",
      "Row 4 mutation indexes: [864, 2450, 2574, 1975, 2727, 2568, 1897, 374, 3065, 2611, 1833, 560, 388, 1275, 722, 631, 2398, 1732, 97, 3068, 1945, 1550, 729, 1221, 1453, 1544, 826, 350, 2668, 2362, 3030, 636, 2055, 185, 2061, 2477, 1282, 1946, 2626, 2775, 100, 2629, 217, 318, 1416, 555, 1942, 105, 1956, 2472, 1339, 1371, 645, 357, 261, 224, 707, 2358, 2329, 2465, 881, 2650, 1411, 2403, 2730, 677, 2378, 2519, 2346, 216, 1713, 1376, 3070, 2118, 2032, 223, 1835]\n",
      "77\n",
      "Row 5 mutation indexes: [864, 2450, 2574, 1975, 2478, 2509, 2727, 2568, 1897, 374, 3065, 2611, 1833, 560, 388, 1275, 722, 631, 2398, 1732, 97, 3068, 1945, 1550, 729, 1812, 1221, 1453, 1544, 826, 350, 2668, 2362, 2517, 3030, 636, 2055, 185, 1794, 2061, 1800, 2477, 1282, 1946, 2626, 2775, 100, 577, 2629, 217, 318, 1416, 2514, 376, 555, 1796, 1942, 105, 1956, 1791, 2472, 1339, 1790, 1371, 645, 357, 261, 224, 2503, 707, 2358, 2329, 1821, 2465, 881, 2650, 1411, 2403, 2730, 677, 2378, 2519, 216, 2346, 1713, 1376, 3070, 2118, 2032, 223, 1835]\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to find mutation encoding and indexes\n",
    "def get_mutation_indexes(detailed_df, site_mutation_df):\n",
    "    # Prepare a list to store the results\n",
    "    all_results = []\n",
    "\n",
    "    # Iterate over each row in detailed_results_df\n",
    "    for index, row in detailed_df.iterrows():\n",
    "        mutations = list(row[\"mutations_observed\"])\n",
    "        mutation_indexes = []\n",
    "\n",
    "        # Iterate through each mutation in the list\n",
    "        for mutation in mutations:\n",
    "            # Extract WT, site, and mutant from the mutation string (e.g., \"Y453F\")\n",
    "            wt = mutation[0]\n",
    "            site = float(mutation[1:-1])\n",
    "            mutant = mutation[-1]\n",
    "\n",
    "            # Find rows in the second dataframe matching mutant and site\n",
    "            matching_rows = site_mutation_df[\n",
    "                (site_mutation_df[\"mutation\"] == mutant) & (site_mutation_df[\"site_SARS2\"] == site)\n",
    "            ]\n",
    "\n",
    "            # Store the indexes of matching rows\n",
    "            mutation_indexes.extend(matching_rows.index.tolist())\n",
    "\n",
    "        # Append the result for the current row\n",
    "        all_results.append(mutation_indexes)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Call the function and print the results\n",
    "mutation_indexes_results = get_mutation_indexes(detailed_results_df, df)\n",
    "for i, indexes in enumerate(mutation_indexes_results):\n",
    "    print(f\"Row {i} mutation indexes: {indexes}\")\n",
    "    print(len(indexes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_indexes(active_learner, date_index):\n",
    "    train_data_u, _ = active_learner.train_dataset.get_data()\n",
    "\n",
    "    train_data_u_indexes = []\n",
    "    for j in range(len(df)):\n",
    "        for i in range(len(train_data_u)):\n",
    "            if df[EMBED][j] == train_data_u[i].tolist():\n",
    "                train_data_u_indexes.append(j)\n",
    "\n",
    "    print(\"indexes checked by embedding\", train_data_u_indexes)\n",
    "\n",
    "    training_set = df.loc[train_data_u_indexes]\n",
    "    # save training set in csv with name training_set_+strategy+\"_run_\"+run\n",
    "    filename = \"../script_results/1_batch_real_direct_esm3_coord/training_set_bloom_1000_date\"+str(date_index)+\".csv\"\n",
    "\n",
    "    # Save the training set to a CSV file\n",
    "    training_set.to_csv(filename, index=False)\n",
    "\n",
    "    hist_indexes = active_learner.get_training_indices_history()\n",
    "    # save as a npy with the right name\n",
    "    # Save the history as a .npy file\n",
    "    print(\"hist_indexes\", hist_indexes)\n",
    "    filename = \"../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date\"+str(date_index)+\".csv\"\n",
    "\n",
    "    # Save list of lists to a CSV file\n",
    "    with open(filename, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(hist_indexes)\n",
    "\n",
    "    print(f\"List of lists saved as CSV to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings of shape torch.Size([3803, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VIRAL\\plots\\../src\\utils.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path)  # Load the tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        mutant_sequence  log10Kd_ACE2  \\\n",
      "0     NITALCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      9.003694   \n",
      "1     NITCLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      8.923694   \n",
      "2     NITDLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      9.103694   \n",
      "3     NITELCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      9.043694   \n",
      "4     NITFLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      8.813694   \n",
      "...                                                 ...           ...   \n",
      "3117  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      9.013694   \n",
      "3118  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      9.043694   \n",
      "3119  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      8.993694   \n",
      "3120  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      8.953694   \n",
      "3121  NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...      9.013694   \n",
      "\n",
      "      delta_log_kd_ACE2 mutation  site_SARS2  mut_escape_LY-CoV016  \\\n",
      "0             -0.003694        A       334.0              0.001044   \n",
      "1              0.076306        C       334.0              0.001667   \n",
      "2             -0.103694        D       334.0              0.001044   \n",
      "3             -0.043694        E       334.0              0.001044   \n",
      "4              0.186306        F       334.0              0.005162   \n",
      "...                 ...      ...         ...                   ...   \n",
      "3117          -0.013694        S       526.0              0.001484   \n",
      "3118          -0.043694        T       526.0              0.001301   \n",
      "3119           0.006306        V       526.0              0.001044   \n",
      "3120           0.046306        W       526.0              0.001044   \n",
      "3121          -0.013694        Y       526.0              0.001301   \n",
      "\n",
      "      mut_escape_REGN10987  mut_escape_LY-CoV555  mut_escape_S309  \\\n",
      "0                 0.002180              0.001778         0.036300   \n",
      "1                 0.002439              0.001778         0.047630   \n",
      "2                 0.002157              0.001778         0.038180   \n",
      "3                 0.002465              0.001778         0.047650   \n",
      "4                 0.002140              0.001778         0.039540   \n",
      "...                    ...                   ...              ...   \n",
      "3117              0.001886              0.001778         0.037210   \n",
      "3118              0.002116              0.001778         0.039256   \n",
      "3119              0.002143              0.001778         0.044280   \n",
      "3120              0.002085              0.001778         0.044780   \n",
      "3121              0.002116              0.001778         0.039256   \n",
      "\n",
      "      log_kd_LY-CoV016  delta_log_kd_LY-CoV016  log_kd_REGN10987  \\\n",
      "0            -2.981300                0.000000         -2.661544   \n",
      "1            -2.778064                0.203235         -2.612788   \n",
      "2            -2.981300                0.000000         -2.666150   \n",
      "3            -2.981300                0.000000         -2.608183   \n",
      "4            -2.287182                0.694118         -2.669586   \n",
      "...                ...                     ...               ...   \n",
      "3117         -2.828566                0.152733         -2.724458   \n",
      "3118         -2.885589                0.095710         -2.674587   \n",
      "3119         -2.981300                0.000000         -2.668978   \n",
      "3120         -2.981300                0.000000         -2.680894   \n",
      "3121         -2.885589                0.095710         -2.674587   \n",
      "\n",
      "      delta_log_kd_REGN10987  log_kd_LY-CoV555  delta_log_kd_LY-CoV555  \\\n",
      "0                   0.030106         -2.750068                     0.0   \n",
      "1                   0.078861         -2.750068                     0.0   \n",
      "2                   0.025499         -2.750068                     0.0   \n",
      "3                   0.083466         -2.750068                     0.0   \n",
      "4                   0.022063         -2.750068                     0.0   \n",
      "...                      ...               ...                     ...   \n",
      "3117               -0.032809         -2.750068                     0.0   \n",
      "3118                0.017062         -2.750068                     0.0   \n",
      "3119                0.022671         -2.750068                     0.0   \n",
      "3120                0.010755         -2.750068                     0.0   \n",
      "3121                0.017062         -2.750068                     0.0   \n",
      "\n",
      "      log_kd_S309  delta_log_kd_S309  bio_model_fitness  \\\n",
      "0       -1.440093           0.022970           1.037860   \n",
      "1       -1.322119           0.140944           1.073980   \n",
      "2       -1.418164           0.044899           1.052569   \n",
      "3       -1.321937           0.141126           1.074046   \n",
      "4       -1.402963           0.060100           1.057044   \n",
      "...           ...                ...                ...   \n",
      "3117    -1.429340           0.033723           1.042360   \n",
      "3118    -1.406094           0.056969           1.053648   \n",
      "3119    -1.353792           0.109271           1.055712   \n",
      "3120    -1.348916           0.114147           1.051746   \n",
      "3121    -1.406094           0.056969           1.050728   \n",
      "\n",
      "                                             esm3_coord  \n",
      "0     [0.38624855875968933, 0.9426648616790771, -0.1...  \n",
      "1     [-0.5910851359367371, -0.9329586029052734, -0....  \n",
      "2     [0.4446234405040741, -0.5124260783195496, 0.09...  \n",
      "3     [0.4795464277267456, -0.06519956141710281, -0....  \n",
      "4     [-0.7210904359817505, 0.23347921669483185, -0....  \n",
      "...                                                 ...  \n",
      "3117  [0.2358502596616745, -1.3161910772323608, -0.1...  \n",
      "3118  [0.09360922873020172, -0.8400347232818604, -0....  \n",
      "3119  [0.6064926385879517, -0.25840431451797485, -0....  \n",
      "3120  [-0.6379890441894531, 0.2682548463344574, -0.5...  \n",
      "3121  [-0.01192447915673256, -0.41265007853507996, -...  \n",
      "\n",
      "[3122 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_kd = pd.read_csv(\"../data_bloom/kd_bloom/df_bloom_processed.csv\")\n",
    "# rename columns site as site_SARS2\n",
    "df_kd.rename(columns={\"site\": \"site_SARS2\"}, inplace=True)\n",
    "\n",
    "\n",
    "train_data = load_esm_embeddings(\"esm3_coord\")\n",
    "\n",
    "\n",
    "targets = [\n",
    "    \"delta_log_kd_ACE2\",\n",
    "    \"delta_log_kd_LY-CoV016\",\n",
    "    \"delta_log_kd_REGN10987\",\n",
    "    \"delta_log_kd_LY-CoV555\",\n",
    "    \"delta_log_kd_S309\",\n",
    "]\n",
    "\n",
    "train_x = torch.tensor(train_data)\n",
    "train_y = torch.tensor(df_kd[targets].values)\n",
    "\n",
    "# Remove rows with NaN\n",
    "indexes_nan = np.unique(np.where(np.isnan(train_y))[0])\n",
    "non_nan_indexes = np.setdiff1d(np.arange(train_y.shape[0]), indexes_nan)\n",
    "\n",
    "train_x = train_x[non_nan_indexes]\n",
    "train_y = train_y[non_nan_indexes]\n",
    "df = df_kd.drop(indexes_nan).reset_index(drop=True)\n",
    "\n",
    "df[EMBED] = train_x.tolist()\n",
    "indexNames = []\n",
    "for i in range(len(df)):\n",
    "    if df[\"site_SARS2\"][i] in [331, 332, 333, 527, 528, 529, 530, 531]:\n",
    "        indexNames.append(i)\n",
    "df.drop(indexNames, inplace=True)\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)\n",
    "train_x = np.delete(train_x, indexNames, axis=0)\n",
    "train_y = np.delete(train_y, indexNames, axis=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new AL object\n",
      "training on  3  points\n",
      "Learned kernel: RationalQuadratic(alpha=1.29e+03, length_scale=592)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.00336, length_scale=311)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.77694360799343, P: 0.33226837060702874, Var: 1.1830344200134277\n",
      "indexes checked by embedding [10, 38, 39, 40, 42, 43, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 86, 87, 88, 89, 90, 91, 92, 114, 115, 117, 120, 122, 123, 125, 129, 130, 135, 138, 139, 144, 148, 152, 153, 154, 156, 162, 163, 166, 209, 214, 216, 218, 225, 232, 253, 270, 271, 273, 282, 283, 292, 325, 326, 328, 361, 362, 365, 366, 368, 369, 372, 377, 385, 396, 399, 400, 401, 402, 404, 405, 406, 409, 410, 411, 412, 413, 414, 416, 418, 422, 423, 434, 437, 438, 444, 446, 452, 453, 456, 457, 458, 459, 460, 461, 462, 463, 464, 466, 467, 468, 469, 470, 472, 473, 474, 480, 513, 514, 515, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 539, 541, 547, 548, 555, 570, 571, 572, 573, 575, 576, 578, 580, 581, 582, 583, 584, 585, 586, 588, 589, 590, 591, 594, 596, 601, 604, 605, 606, 608, 613, 623, 624, 627, 643, 686, 687, 688, 698, 699, 700, 703, 708, 710, 727, 741, 743, 744, 745, 747, 751, 752, 755, 756, 757, 760, 764, 765, 767, 768, 771, 774, 775, 776, 777, 778, 779, 780, 781, 782, 784, 791, 794, 796, 804, 807, 817, 819, 822, 828, 832, 836, 840, 841, 843, 845, 846, 851, 852, 855, 857, 858, 859, 860, 861, 862, 866, 870, 871, 872, 875, 890, 893, 900, 901, 904, 909, 912, 913, 914, 915, 917, 918, 920, 922, 923, 924, 925, 926, 927, 928, 930, 931, 938, 940, 947, 950, 956, 966, 974, 994, 996, 1004, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1016, 1017, 1019, 1020, 1021, 1022, 1023, 1026, 1031, 1050, 1052, 1066, 1069, 1075, 1079, 1083, 1084, 1085, 1086, 1088, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1099, 1100, 1103, 1104, 1105, 1106, 1108, 1109, 1112, 1113, 1116, 1121, 1123, 1125, 1132, 1156, 1157, 1160, 1164, 1167, 1171, 1172, 1177, 1180, 1189, 1190, 1196, 1198, 1200, 1208, 1233, 1236, 1241, 1245, 1246, 1253, 1254, 1260, 1275, 1277, 1284, 1292, 1294, 1308, 1309, 1311, 1316, 1319, 1344, 1350, 1352, 1355, 1359, 1360, 1365, 1372, 1406, 1440, 1480, 1498, 1501, 1513, 1515, 1517, 1518, 1520, 1521, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1538, 1540, 1549, 1550, 1553, 1557, 1564, 1568, 1569, 1572, 1573, 1574, 1575, 1576, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1596, 1612, 1613, 1615, 1616, 1622, 1625, 1627, 1631, 1634, 1640, 1650, 1652, 1654, 1657, 1660, 1661, 1664, 1671, 1672, 1674, 1683, 1725, 1740, 1743, 1745, 1764, 1765, 1766, 1769, 1771, 1772, 1778, 1779, 1788, 1797, 1862, 1864, 1866, 1867, 1869, 1873, 1876, 1878, 1879, 1881, 1883, 1884, 1885, 1887, 1888, 1889, 1892, 1893, 1895, 1899, 1902, 1904, 1911, 1956, 1959, 1961, 1962, 1969, 2010, 2013, 2014, 2016, 2017, 2018, 2024, 2025, 2028, 2035, 2037, 2044, 2069, 2083, 2085, 2092, 2093, 2100, 2101, 2109, 2111, 2113, 2114, 2119, 2120, 2123, 2129, 2134, 2139, 2142, 2143, 2144, 2145, 2146, 2148, 2150, 2151, 2152, 2153, 2155, 2157, 2158, 2159, 2160, 2161, 2166, 2170, 2177, 2178, 2199, 2203, 2206, 2208, 2212, 2215, 2225, 2234, 2237, 2240, 2243, 2245, 2246, 2252, 2253, 2275, 2277, 2279, 2280, 2282, 2284, 2298, 2301, 2303, 2310, 2319, 2321, 2329, 2351, 2367, 2394, 2405, 2408, 2415, 2424, 2433, 2443, 2471, 2518, 2519, 2529, 2538, 2541, 2546, 2564, 2566, 2576, 2584, 2598, 2599, 2602, 2605, 2607, 2610, 2614, 2617, 2621, 2624, 2626, 2632, 2633, 2662, 2671, 2676, 2690, 2728, 2769, 2770, 2774, 2776, 2782, 2784, 2785, 2786, 2790, 2791, 2809, 2810, 2811, 2813, 2814, 2816, 2817, 2819, 2822, 2823, 2824, 2825, 2826, 2828, 2829, 2831, 2833, 2835, 2836, 2838, 2841, 2843, 2847, 2848, 2850, 2854, 2857, 2858, 2859, 2883, 2884, 2885, 2888, 2893, 2894, 2897, 2898, 2902, 2907, 2909, 2911, 2914, 2918, 2921, 2922, 2923, 2925, 2927, 2929, 2932, 2935, 2936, 2937, 2940, 2944, 2956, 2997, 3012, 3030, 3035, 3074]\n",
      "hist_indexes [[555, 1956, 3030], [2471, 2944, 1725, 1674, 1568, 901, 1026, 2109, 10, 2321, 2607, 1233, 2728, 791, 460, 804, 2566, 2621, 710, 1533, 1157, 940, 2085, 2144, 2246, 2160, 2632, 400, 2240, 1889, 1899, 1532, 780, 1309, 1116, 1869, 828, 88, 292, 2252, 1661, 782, 2083, 2610, 1527, 1797, 2134, 768, 2854, 2541, 1241, 2415, 418, 931, 1866, 271, 2014, 422, 794, 1196, 2598, 2114, 2170, 1534, 1352, 2408, 2279, 2605, 214, 423, 586, 1050, 2212, 2676, 396, 2858, 2518, 2671, 1740, 326, 1573, 2143, 1052, 747, 1549, 1253, 1480, 1873, 1097, 1530, 2841, 1513, 2119, 2909, 1294, 1888, 2237, 2351, 2024, 55, 2028, 774, 71, 405, 2690, 81, 2784, 3074, 1016, 2093, 2929, 1778, 270, 1884, 1501, 2177, 938, 1867, 328, 2120, 1440, 75, 1121, 1862, 53, 900, 2822, 956, 2100, 2662, 406, 1962, 1745, 1108, 1743, 2626, 1518, 1521, 698, 1616, 947, 519, 775, 2151, 1316, 1292, 89, 1112, 1132, 1277, 438, 872, 1531, 777, 1578, 1564, 1625, 1023, 1772, 778, 2203, 368, 1622, 225, 59, 1557, 861, 52, 474, 1683, 139, 2614, 1012, 2791, 700, 2932, 283, 2519, 890, 573, 623, 624, 470, 2617, 1156, 893, 1579, 2275, 2790, 38, 1319, 2782, 461, 627, 3012, 2835, 858, 1671, 70, 416, 3035, 1372, 1172, 862, 48, 588, 92, 1895, 2850, 2443, 1160, 2284, 807, 209, 687, 2836, 144, 218, 153, 2433, 2599, 2225, 859, 2329, 1788, 1887, 91, 2922, 840, 434, 1094, 928, 613, 1879, 154, 1864, 2546, 54, 2234, 2529, 1885, 846, 1660, 365, 148, 1657, 2776, 2155, 1406, 996, 2013, 1180, 2564, 1190, 411, 1596, 2069, 1581, 63, 362, 601, 480, 756, 2018, 456, 2277, 2178, 930, 2157, 2997, 2833, 129, 369, 2893, 751, 1245, 1766, 2911, 2584, 2298, 1640, 1086, 2769, 699, 135, 1123, 1904, 1769, 2113, 2199, 361, 2918, 703, 767, 459, 1275, 1892, 904, 925, 125, 468, 67, 1355, 1765, 1167, 1575, 2282, 1260, 2843, 522, 1200, 2044, 253, 1969, 2914, 855, 2770, 2819, 2208, 2576, 1515, 2319, 1104, 2538, 1109, 817, 1359, 123, 1538, 1550, 596, 2310, 547, 1031, 377, 2927, 708, 2146, 1008, 832, 2129, 1007, 282, 2123, 1208, 216, 1779, 1771, 399, 78, 1177, 2394, 1164, 1961, 1672, 974, 2785, 46, 42, 1099, 152, 2245, 2367, 2111, 1106, 273, 523, 464, 1652, 1498, 1650, 166, 2848, 539, 920, 532, 2817, 1198, 845, 2161, 1540, 857, 755, 2921, 582, 1878, 851, 1189, 1529, 2936, 457, 923, 2280, 2301, 2602, 2825, 870, 43, 2935, 2142, 1020, 1569, 2940, 1902, 871, 994, 2017, 2829, 2923, 1553, 162, 1079, 1125, 1096, 2303, 1627, 1583, 2010, 2405, 1580, 114, 1090, 1092, 604, 1634, 950, 446, 473, 325, 578, 781, 74, 583, 581, 796, 875, 2139, 2037, 1344, 1764, 39, 541, 757, 1911, 1613, 1582, 727, 1013, 117, 608, 2153, 472, 760, 462, 2424, 2243, 64, 372, 72, 2774, 2956, 744, 2823, 590, 771, 1113, 163, 2816, 1019, 2884, 591, 909, 1959, 525, 866, 836, 466, 2898, 66, 2159, 458, 77, 2786, 2859, 1284, 2035, 1588, 819, 1004, 452, 605, 2633, 2813, 2902, 784, 2166, 2206, 776, 779, 924, 1584, 2092, 86, 1084, 444, 1585, 1517, 2814, 686, 73, 1311, 643, 1631, 62, 966, 1664, 58, 2624, 2145, 1093, 1881, 2885, 414, 1574, 2253, 2857, 87, 1100, 1022, 232, 2152, 463, 841, 2810, 1883, 2101, 2016, 2937, 764, 61, 1365, 76, 467, 927, 2150, 1171, 57, 1612, 1350, 1893, 2025, 1654, 1587, 576, 409, 527, 1586, 1876, 385, 2826, 402, 1254, 2148, 688, 2811, 115, 1021, 469, 90, 1246, 50, 1236, 918, 913, 1085, 1360, 437, 860, 40, 2824, 1520, 1308, 453, 410, 1103, 572, 585, 2828, 2809, 1572, 743, 2158, 122, 412, 912, 548, 521, 524, 571, 45, 1069, 843, 2907, 413, 51, 752, 520, 1075, 915, 822, 2215, 589, 120, 516, 1105, 606, 765, 1615, 926, 130, 404, 1095, 1017, 526, 530, 529, 594, 514, 515, 2925, 1083, 852, 2847, 2838, 741, 138, 580, 2883, 570, 80, 1011, 2894, 1010, 528, 922, 518, 1066, 513, 745, 366, 2897, 1576, 1088, 401, 156, 917, 584, 2831, 914, 2888, 1009, 575]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date0.csv\n",
      "created new AL object\n",
      "training on  14  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.000891, length_scale=1e-05)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned kernel: RationalQuadratic(alpha=0.0007, length_scale=26.8)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.5890523770417009, P: 0.16613418530351437, Var: 0.5326253175735474\n",
      "indexes checked by embedding [2, 3, 5, 11, 12, 14, 15, 29, 30, 31, 34, 35, 78, 79, 84, 88, 94, 97, 105, 106, 110, 116, 136, 140, 142, 160, 172, 173, 182, 183, 186, 201, 202, 203, 205, 221, 222, 228, 230, 231, 238, 239, 240, 243, 244, 246, 248, 249, 261, 262, 266, 268, 269, 271, 277, 278, 279, 281, 285, 287, 288, 289, 290, 291, 292, 295, 296, 297, 298, 301, 302, 303, 305, 306, 312, 314, 315, 316, 318, 319, 320, 326, 342, 344, 345, 354, 357, 358, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 388, 392, 420, 421, 429, 430, 431, 433, 439, 482, 486, 487, 491, 495, 496, 498, 505, 506, 508, 509, 543, 545, 547, 551, 553, 555, 560, 562, 563, 564, 567, 593, 642, 657, 661, 665, 667, 668, 670, 676, 678, 680, 692, 703, 705, 706, 714, 715, 716, 718, 719, 722, 724, 725, 731, 735, 738, 740, 759, 760, 762, 763, 765, 766, 767, 768, 770, 771, 772, 773, 774, 775, 776, 778, 781, 783, 798, 800, 801, 808, 809, 810, 812, 813, 817, 820, 821, 835, 838, 847, 848, 876, 898, 903, 905, 906, 908, 919, 981, 984, 1025, 1028, 1029, 1039, 1047, 1048, 1056, 1057, 1060, 1071, 1085, 1116, 1118, 1119, 1121, 1129, 1135, 1137, 1138, 1142, 1148, 1150, 1151, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1194, 1203, 1252, 1265, 1289, 1290, 1314, 1315, 1322, 1326, 1327, 1329, 1337, 1393, 1394, 1401, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1428, 1431, 1432, 1434, 1435, 1436, 1440, 1443, 1479, 1480, 1481, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1519, 1522, 1526, 1590, 1593, 1603, 1645, 1669, 1670, 1678, 1686, 1688, 1689, 1691, 1699, 1701, 1707, 1713, 1726, 1732, 1735, 1746, 1750, 1754, 1755, 1759, 1762, 1764, 1765, 1767, 1773, 1774, 1775, 1777, 1781, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1799, 1802, 1805, 1807, 1809, 1811, 1812, 1813, 1816, 1819, 1829, 1830, 1840, 1848, 1849, 1857, 1859, 1860, 1871, 1872, 1880, 1897, 1900, 1907, 1909, 1910, 1916, 1917, 1918, 1921, 1932, 1933, 1935, 1936, 1937, 1940, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1951, 1954, 1955, 1956, 1970, 1973, 1974, 1978, 1982, 1986, 1987, 1990, 1992, 1993, 1998, 2001, 2002, 2005, 2008, 2009, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2027, 2030, 2039, 2040, 2041, 2043, 2044, 2049, 2050, 2058, 2059, 2062, 2066, 2068, 2069, 2070, 2076, 2077, 2078, 2080, 2081, 2082, 2084, 2085, 2090, 2095, 2096, 2097, 2099, 2100, 2106, 2107, 2125, 2131, 2141, 2144, 2161, 2163, 2164, 2165, 2166, 2167, 2168, 2170, 2172, 2173, 2174, 2175, 2176, 2177, 2179, 2182, 2184, 2188, 2190, 2191, 2196, 2201, 2210, 2214, 2218, 2220, 2229, 2230, 2231, 2239, 2267, 2271, 2275, 2277, 2278, 2279, 2287, 2288, 2291, 2292, 2296, 2297, 2306, 2314, 2315, 2324, 2325, 2327, 2328, 2329, 2334, 2356, 2362, 2363, 2366, 2370, 2372, 2381, 2382, 2383, 2385, 2410, 2419, 2420, 2429, 2437, 2438, 2453, 2458, 2459, 2462, 2467, 2472, 2486, 2494, 2495, 2505, 2509, 2511, 2514, 2515, 2519, 2521, 2524, 2525, 2527, 2534, 2545, 2553, 2560, 2568, 2570, 2571, 2572, 2574, 2575, 2578, 2581, 2582, 2583, 2589, 2591, 2595, 2597, 2617, 2622, 2628, 2629, 2630, 2632, 2636, 2638, 2646, 2647, 2650, 2651, 2657, 2658, 2666, 2704, 2712, 2714, 2715, 2716, 2724, 2726, 2727, 2728, 2730, 2733, 2734, 2738, 2740, 2742, 2743, 2744, 2747, 2750, 2752, 2753, 2760, 2761, 2762, 2771, 2773, 2830, 2871, 2904, 2905, 2913, 2915, 2917, 2942, 2961, 2970, 2974, 2980, 2982, 2985, 2988, 2990, 2994, 3008, 3009, 3017, 3018, 3020, 3028, 3030, 3031, 3055, 3056, 3058, 3064, 3065, 3066, 3068, 3069, 3070, 3073, 3074, 3075, 3077, 3081, 3114]\n",
      "hist_indexes [[388, 555, 1411, 1713, 1732, 1946, 1956, 2362, 2472, 2629, 2727, 2730, 3030, 3068], [498, 1848, 2291, 3018, 1025, 2329, 2570, 906, 358, 2218, 228, 642, 2420, 3074, 2410, 740, 1943, 318, 2100, 2044, 1754, 1645, 919, 203, 1805, 2271, 3009, 1085, 2267, 1982, 486, 2734, 2287, 551, 1790, 1056, 342, 2982, 1910, 1998, 2753, 1699, 668, 244, 506, 142, 1519, 781, 110, 2016, 759, 2005, 2575, 714, 508, 810, 2773, 3066, 1489, 1443, 984, 1194, 2771, 2296, 2382, 1921, 2002, 2574, 1816, 798, 3073, 731, 1522, 1940, 981, 2385, 1322, 182, 1750, 14, 491, 1315, 1434, 2099, 817, 1493, 243, 898, 1764, 2090, 835, 392, 1494, 676, 908, 2494, 1337, 2, 1440, 2545, 562, 1071, 1849, 2324, 2560, 1678, 2595, 3008, 1526, 2628, 295, 1148, 2141, 1909, 1990, 2650, 1860, 2704, 2429, 2728, 1954, 1039, 2210, 1150, 1116, 2636, 2080, 2066, 2191, 2190, 303, 2961, 2167, 3070, 1488, 2486, 1774, 1121, 560, 326, 2184, 291, 2458, 2505, 1819, 2519, 29, 2521, 378, 5, 205, 240, 1829, 1872, 1947, 482, 222, 593, 140, 505, 2744, 105, 88, 1490, 547, 2658, 1418, 2372, 2572, 290, 665, 1773, 719, 249, 820, 2651, 2370, 2144, 1691, 3064, 277, 34, 661, 2107, 813, 239, 2327, 2980, 3075, 2220, 1970, 3077, 2762, 2747, 1813, 1428, 2085, 1973, 3081, 1840, 2589, 2726, 2515, 2646, 2459, 1935, 2534, 3114, 2712, 703, 1830, 221, 1765, 2438, 821, 2527, 2988, 319, 1775, 1486, 3058, 2062, 285, 2182, 2871, 722, 1802, 1029, 1432, 2970, 1048, 1701, 370, 3028, 2591, 1431, 496, 1746, 1986, 2231, 495, 2059, 509, 1135, 2553, 183, 312, 838, 1686, 2328, 1871, 1857, 1933, 2462, 2742, 2275, 1420, 735, 2383, 160, 314, 316, 366, 1900, 2164, 1807, 186, 1811, 2525, 15, 1951, 1203, 279, 1265, 771, 1590, 1393, 1252, 2325, 1314, 238, 431, 765, 2381, 2716, 2001, 261, 1329, 2942, 1955, 116, 1060, 262, 1907, 1118, 1880, 306, 1784, 11, 715, 1175, 1670, 2196, 2750, 1190, 2082, 3056, 35, 2279, 692, 1948, 78, 567, 3055, 3020, 2306, 1129, 725, 2015, 2583, 1603, 320, 553, 1028, 2188, 429, 2738, 2994, 670, 2715, 3, 2974, 301, 1987, 809, 2166, 2657, 2913, 1498, 271, 3031, 1949, 1176, 2632, 173, 2666, 1593, 1481, 1142, 2297, 1788, 564, 3069, 2990, 2070, 2292, 136, 1787, 1137, 1936, 848, 1932, 2084, 1974, 2760, 357, 1513, 2985, 766, 2239, 1436, 778, 2027, 2214, 2453, 79, 2733, 738, 2163, 289, 2013, 2022, 706, 1785, 2740, 1799, 563, 1735, 1057, 3017, 84, 2915, 2025, 1993, 296, 487, 1809, 801, 767, 680, 2168, 2170, 2509, 2366, 281, 172, 903, 2724, 2131, 354, 763, 1978, 2106, 230, 1786, 1499, 30, 2008, 2179, 31, 363, 2229, 1944, 2095, 1689, 297, 2161, 2076, 2081, 246, 783, 2581, 1759, 94, 762, 545, 201, 1394, 678, 2597, 2495, 2125, 2288, 2315, 2314, 439, 2568, 2467, 2017, 2571, 876, 302, 1138, 1327, 2356, 292, 2058, 2630, 905, 364, 367, 298, 1726, 2904, 1480, 1945, 1180, 2617, 2077, 2165, 2039, 1783, 2177, 1916, 812, 2511, 2277, 718, 12, 1992, 2830, 1435, 667, 808, 768, 2334, 1917, 248, 2201, 724, 1918, 231, 1119, 2050, 543, 2230, 2069, 1422, 2419, 372, 266, 1479, 657, 1179, 2068, 2638, 2030, 2582, 315, 2622, 1755, 1789, 2917, 2278, 1767, 773, 345, 705, 2905, 2514, 1151, 1189, 2743, 1777, 1897, 1183, 1781, 2172, 2175, 2761, 1502, 433, 2437, 1326, 2173, 2752, 2578, 2043, 847, 97, 1762, 1047, 2176, 1177, 1688, 1937, 1423, 1289, 2096, 421, 774, 2049, 379, 202, 305, 2041, 1509, 716, 1191, 1795, 1410, 1500, 2012, 365, 776, 106, 269, 1405, 1794, 2363, 430, 2097, 1290, 369, 2078, 1406, 760, 1501, 2714, 1797, 2174, 1419, 1793, 1505, 374, 1182, 2011, 1707, 368, 2647, 1514, 287, 1792, 1503, 268, 420, 1504, 288, 1414, 1187, 2040, 800, 1408, 1407, 1859, 1178, 1796, 2014, 1185, 377, 1510, 1403, 3065, 361, 1812, 2009, 2524, 1791, 1669, 775, 1409, 1186, 375, 371, 1184, 2024, 1417, 1496, 2021, 376, 1512, 344, 2023, 1173, 772, 1188, 2019, 1404, 1507, 278, 770, 373, 1415, 1511, 2020, 1508, 1401, 1416, 1506, 1412, 1413]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date1.csv\n",
      "created new AL object\n",
      "training on  23  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.00695, length_scale=69.2)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.37 MiB for an array with shape (665, 665) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m dataset_0 \u001b[38;5;241m=\u001b[39m Dataset_perso(train_0_x, train_0_y)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Run the active learner and collect r2, p, and var\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m r2_list, p_list, var_list, active_learner \u001b[38;5;241m=\u001b[39m run_active_learner(\n\u001b[0;32m     30\u001b[0m     strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m     31\u001b[0m     dataset_0\u001b[38;5;241m=\u001b[39mdataset_0,\n\u001b[0;32m     32\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m     33\u001b[0m     NB_POINTS\u001b[38;5;241m=\u001b[39mNB_POINTS,\n\u001b[0;32m     34\u001b[0m     NB_ROUNDS\u001b[38;5;241m=\u001b[39mNB_ROUNDS,\n\u001b[0;32m     35\u001b[0m     biomodel\u001b[38;5;241m=\u001b[39mbiomodel,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Collect results for the single round (end of round 1)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_dates\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_dates[date_index],\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m: indexes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m\"\u001b[39m: var_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# Last value of var (end of round 1)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m })\n",
      "File \u001b[1;32me:\\VIRAL\\plots\\../src\\hist_al_utils.py:102\u001b[0m, in \u001b[0;36mrun_active_learner\u001b[1;34m(strategy, dataset_0, dataset, NB_POINTS, NB_ROUNDS, biomodel)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NB_ROUNDS):\n\u001b[0;32m    101\u001b[0m     active_learner\u001b[38;5;241m.\u001b[39mget_next_points(nb_points\u001b[38;5;241m=\u001b[39mNB_POINTS)\n\u001b[1;32m--> 102\u001b[0m     active_learner\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    103\u001b[0m     p, r2, var \u001b[38;5;241m=\u001b[39m active_learner\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m    104\u001b[0m     r2_list\u001b[38;5;241m.\u001b[39mappend(r2)\n",
      "File \u001b[1;32me:\\VIRAL\\plots\\../src\\active_learner.py:128\u001b[0m, in \u001b[0;36mActiveLearner.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# fing unique points\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp \u001b[38;5;241m=\u001b[39m gp_predictor_sklearn(train_x, train_y)\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp\u001b[38;5;241m.\u001b[39mtrain_pred()\n",
      "File \u001b[1;32me:\\VIRAL\\plots\\../src\\gaussian_process.py:23\u001b[0m, in \u001b[0;36mgp_predictor_sklearn.train_pred\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_pred\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Fit the GP model to the training data\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_y)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearned kernel: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mkernel_)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:307\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[0;32m    305\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    306\u001b[0m     (\n\u001b[1;32m--> 307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constrained_optimization(\n\u001b[0;32m    308\u001b[0m             obj_func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_\u001b[38;5;241m.\u001b[39mtheta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_\u001b[38;5;241m.\u001b[39mbounds\n\u001b[0;32m    309\u001b[0m         )\n\u001b[0;32m    310\u001b[0m     )\n\u001b[0;32m    311\u001b[0m ]\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:656\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 656\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m    657\u001b[0m             obj_func,\n\u001b[0;32m    658\u001b[0m             initial_theta,\n\u001b[0;32m    659\u001b[0m             method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    660\u001b[0m             jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    661\u001b[0m             bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    662\u001b[0m         )\n\u001b[0;32m    663\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[0;32m    664\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:347\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    344\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    348\u001b[0m                               bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    349\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[0;32m    351\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    353\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    289\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:166\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:297\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 297\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(\n\u001b[0;32m    298\u001b[0m             theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    299\u001b[0m         )\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:580\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    577\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 580\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    582\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:1922\u001b[0m, in \u001b[0;36mRationalQuadratic.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1920\u001b[0m dists \u001b[38;5;241m=\u001b[39m squareform(pdist(X, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1921\u001b[0m tmp \u001b[38;5;241m=\u001b[39m dists \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_scale\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 1922\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m tmp\n\u001b[0;32m   1923\u001b[0m K \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n\u001b[0;32m   1924\u001b[0m np\u001b[38;5;241m.\u001b[39mfill_diagonal(K, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.37 MiB for an array with shape (665, 665) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get end dates from detailed_results_df\n",
    "end_dates = detailed_results_df['end_date'].values\n",
    "\n",
    "# Prepare a list to hold all rows for the final dataframe\n",
    "results = []\n",
    "\n",
    "# Define biomodel and strategy\n",
    "biomodel = 'direct'\n",
    "strategy = 'greedy'\n",
    "\n",
    "# Loop through mutation indexes and process results\n",
    "for date_index, indexes in enumerate(mutation_indexes_results):\n",
    "    NB_0 = len(indexes)  # Initial number of points\n",
    "    NB_POINTS = 500 + 165 - NB_0  # Total points to use\n",
    "    NB_ROUNDS = 1  # Only one round\n",
    "\n",
    "    # Prepare initial training data\n",
    "    train_0_indexes = indexes\n",
    "    train_0_x = torch.stack([dataset.data_x[i] for i in train_0_indexes])\n",
    "    train_0_y = torch.stack([dataset.data_y[i] for i in train_0_indexes])\n",
    "    dataset_0 = Dataset_perso(train_0_x, train_0_y)\n",
    "\n",
    "    # Run the active learner and collect r2, p, and var\n",
    "    r2_list, p_list, var_list, active_learner = run_active_learner(\n",
    "        strategy=strategy,\n",
    "        dataset_0=dataset_0,\n",
    "        dataset=dataset,\n",
    "        NB_POINTS=NB_POINTS,\n",
    "        NB_ROUNDS=NB_ROUNDS,\n",
    "        biomodel=biomodel,\n",
    "    )\n",
    "\n",
    "    # Collect results for the single round (end of round 1)\n",
    "    results.append({\n",
    "        \"end_dates\": end_dates[date_index],\n",
    "        \"indexes\": indexes,\n",
    "        \"p\": p_list[-1],   # Last value of p (end of round 1)\n",
    "        \"r2\": r2_list[-1], # Last value of r2 (end of round 1)\n",
    "        \"var\": var_list[-1] # Last value of var (end of round 1)\n",
    "    })\n",
    "\n",
    "    save_indexes(active_learner, date_index)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Convert the results list into a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    end_dates         p        r2       var  \\\n",
      "0  2020-06-30  0.335463  0.781978  1.182352   \n",
      "1  2020-12-31  0.175719  0.593399  0.533985   \n",
      "2  2021-06-30  0.175719  0.600066  0.568055   \n",
      "3  2021-12-31  0.258786  0.699422  1.007511   \n",
      "4  2022-06-30  0.271565  0.706349  0.836747   \n",
      "5  2022-12-31  0.277955  0.680278  0.854968   \n",
      "\n",
      "                                             indexes  \n",
      "0                                  [555, 3030, 1956]  \n",
      "1  [2629, 388, 1946, 2727, 3068, 1411, 2362, 1956...  \n",
      "2  [2629, 1544, 2329, 217, 2362, 2574, 3030, 1416...  \n",
      "3  [2629, 1544, 2358, 826, 350, 2450, 2668, 217, ...  \n",
      "4  [864, 2450, 2574, 1975, 2727, 2568, 1897, 374,...  \n",
      "5  [864, 2450, 2574, 1975, 2478, 2509, 2727, 2568...  \n"
     ]
    }
   ],
   "source": [
    "results_df = results_df[[\"end_dates\", \"p\", \"r2\", \"var\", \"indexes\"]]\n",
    "\n",
    "# Display or save the dataframe\n",
    "print(results_df)\n",
    "results_df.to_csv(\"../script_results/1_batch_real_direct_esm3_coord/bloom_1_batch_real_1000.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     end_dates         p        r2       var  \\\n",
    "# 0  2020-06-30  0.335463  0.781978  1.182352   \n",
    "# 1  2020-12-31  0.175719  0.593399  0.533985   \n",
    "# 2  2021-06-30  0.175719  0.600066  0.568055   \n",
    "# 3  2021-12-31  0.258786  0.699422  1.007511   \n",
    "# 4  2022-06-30  0.271565  0.706349  0.836747   \n",
    "# 5  2022-12-31  0.277955  0.680278  0.854968 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
