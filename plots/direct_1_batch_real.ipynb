{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a one batch acquisition using the variants/mutations that were found in Gisaid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#import * from utils, gaussian_process, active_learner in ../src\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import *\n",
    "from gaussian_process import *\n",
    "from active_learner import *\n",
    "from hist_al import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get gisaid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>count</th>\n",
       "      <th>q05_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>3980832</td>\n",
       "      <td>2021-06-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1297376</td>\n",
       "      <td>2022-01-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1219498</td>\n",
       "      <td>2022-06-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>1094468</td>\n",
       "      <td>2021-01-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>816046</td>\n",
       "      <td>2020-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25723</th>\n",
       "      <td>NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25724</th>\n",
       "      <td>DITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-18 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25725 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     seq    count  \\\n",
       "0      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  3980832   \n",
       "1      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  1297376   \n",
       "2      NITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNFAPFFA...  1219498   \n",
       "3      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...  1094468   \n",
       "4      NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...   816046   \n",
       "...                                                  ...      ...   \n",
       "25720  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25721  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25722  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25723  NITNLCPFDEVFNATTFASVYAWNRKRISNCVADYSVLYNFAPFFA...        1   \n",
       "25724  DITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFST...        1   \n",
       "\n",
       "                  q05_date  \n",
       "0      2021-06-29 00:00:00  \n",
       "1      2022-01-31 00:00:00  \n",
       "2      2022-06-11 00:00:00  \n",
       "3      2021-01-18 00:00:00  \n",
       "4      2020-03-26 00:00:00  \n",
       "...                    ...  \n",
       "25720  2023-01-02 00:00:00  \n",
       "25721  2023-01-12 00:00:00  \n",
       "25722  2022-10-19 00:00:00  \n",
       "25723  2022-10-31 00:00:00  \n",
       "25724  2021-02-18 00:00:00  \n",
       "\n",
       "[25725 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbd_df=pd.read_csv('../gisaid/rbd_dates.csv', sep=',')\n",
    "rbd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMS dataset (Bloom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>unique_sequences</th>\n",
       "      <th>unique_mutations</th>\n",
       "      <th>mutations_observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{A520S, Y453F, V367F}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>{K417N, S477N, Y453F, N440K, V367F, N439K, L45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>{Y453F, L452R, N501Y, R346S, L452Q, S494P, T47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>86</td>\n",
       "      <td>64</td>\n",
       "      <td>{V382L, A344S, Y453F, G339D, Q414R, T385I, A35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>116</td>\n",
       "      <td>77</td>\n",
       "      <td>{D405N, T385I, S373P, F490L, S371L, A348S, F48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>156</td>\n",
       "      <td>91</td>\n",
       "      <td>{D405N, E484R, T385I, S373P, K444T, F490L, S37...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date    end_date  unique_sequences  unique_mutations  \\\n",
       "0  2020-01-01  2020-06-30                 4                 3   \n",
       "1  2020-01-01  2020-12-31                15                14   \n",
       "2  2020-01-01  2021-06-30                35                23   \n",
       "3  2020-01-01  2021-12-31                86                64   \n",
       "4  2020-01-01  2022-06-30               116                77   \n",
       "5  2020-01-01  2022-12-31               156                91   \n",
       "\n",
       "                                  mutations_observed  \n",
       "0                              {A520S, Y453F, V367F}  \n",
       "1  {K417N, S477N, Y453F, N440K, V367F, N439K, L45...  \n",
       "2  {Y453F, L452R, N501Y, R346S, L452Q, S494P, T47...  \n",
       "3  {V382L, A344S, Y453F, G339D, Q414R, T385I, A35...  \n",
       "4  {D405N, T385I, S373P, F490L, S371L, A348S, F48...  \n",
       "5  {D405N, E484R, T385I, S373P, K444T, F490L, S37...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function get_mutation\n",
    "def get_mutation(WT, sequences):\n",
    "    \"\"\"\n",
    "    Function to determine mutations from the WT sequence given a list of sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    - WT (str): The wild-type (reference) sequence.\n",
    "    - sequences (list): List of sequences to analyze for mutations.\n",
    "    \n",
    "    Returns:\n",
    "    - set: A set of mutations, where each mutation is represented as WT+site+mutant.\n",
    "    \"\"\"\n",
    "    mutations = set()\n",
    "    \n",
    "    # Iterate through each sequence in the list\n",
    "    for seq in sequences:\n",
    "        # Ensure sequences are of the same length to allow site-based comparison\n",
    "        if len(seq) != len(WT):\n",
    "            continue\n",
    "        \n",
    "        # Compare each site in the sequence to the WT\n",
    "        for i, (wt_residue, mutant_residue) in enumerate(zip(WT, seq), start=1):\n",
    "            if wt_residue != mutant_residue:\n",
    "                # Format the mutation as WT+site+mutant (e.g., \"A12G\" for a mutation from A to G at position 12)\n",
    "                mutation = f\"{wt_residue}{i+330}{mutant_residue}\"\n",
    "                mutations.add(mutation)\n",
    "                \n",
    "    return mutations\n",
    "\n",
    "# Define WT sequence\n",
    "WT_sequence = \"NITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\"\n",
    "\n",
    "# Define date intervals for subsets\n",
    "intervals = [\n",
    "    (\"2020-01-01\", \"2020-06-30\"),\n",
    "    (\"2020-01-01\", \"2020-12-31\"),\n",
    "    (\"2020-01-01\", \"2021-06-30\"),\n",
    "    (\"2020-01-01\", \"2021-12-31\"),\n",
    "    (\"2020-01-01\", \"2022-06-30\"),\n",
    "    (\"2020-01-01\", \"2022-12-31\")\n",
    "]\n",
    "# Initialize list to store detailed results\n",
    "detailed_results = []\n",
    "\n",
    "# Iterate over each date interval, similar to previous analysis\n",
    "for start_date, end_date in intervals:\n",
    "    # Filter by date range\n",
    "    subset = rbd_df[(rbd_df['q05_date'] >= start_date) & (rbd_df['q05_date'] <= end_date)]\n",
    "    subset = subset[subset['count'] >= 1000]\n",
    "    \n",
    "    # Get unique sequences in the subset\n",
    "    unique_sequences = subset['seq'].unique()\n",
    "    \n",
    "    # Calculate mutations using the get_mutation function\n",
    "    mutations = get_mutation(WT_sequence, unique_sequences)\n",
    "    \n",
    "    # Append result for the current subset\n",
    "    detailed_results.append({\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'unique_sequences': len(unique_sequences),\n",
    "        'unique_mutations': len(mutations),\n",
    "        'mutations_observed': mutations\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for easy display\n",
    "detailed_results_df = pd.DataFrame(detailed_results)\n",
    "detailed_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A520S', 'Y453F', 'V367F']\n",
      "['K417N', 'S477N', 'Y453F', 'N440K', 'V367F', 'N439K', 'L452R', 'N501Y', 'A520S', 'R357K', 'A522S', 'S494P', 'N501T', 'E484K']\n",
      "['Y453F', 'L452R', 'N501Y', 'R346S', 'L452Q', 'S494P', 'T478K', 'D427N', 'K417N', 'A522S', 'F490S', 'E484Q', 'K417T', 'A520S', 'R357K', 'N501T', 'E484K', 'S477N', 'A475V', 'N440K', 'V367F', 'N439K', 'R346K']\n",
      "['V382L', 'A344S', 'Y453F', 'G339D', 'Q414R', 'T385I', 'A352S', 'L452R', 'A419S', 'N501Y', 'P463S', 'N354T', 'S373P', 'R346S', 'P479L', 'L452Q', 'S494P', 'T478K', 'E484A', 'S375F', 'D427N', 'K417N', 'Y505H', 'A411S', 'P384L', 'R346I', 'F490L', 'S371L', 'G496S', 'G446S', 'A522S', 'F490S', 'V367L', 'A348S', 'Q498R', 'N354K', 'Q493R', 'V483F', 'E484Q', 'K417T', 'A520S', 'T376I', 'R357K', 'G476S', 'N501T', 'E484K', 'S494L', 'L455F', 'S477N', 'P479S', 'S477I', 'A475V', 'N440K', 'V367F', 'R408I', 'N439K', 'S459F', 'N460S', 'D427V', 'K356R', 'R346K', 'G446V', 'Q414K', 'A522V']\n",
      "['D405N', 'T385I', 'S373P', 'F490L', 'S371L', 'A348S', 'F486V', 'S371Y', 'R408S', 'E484Q', 'N450D', 'S494L', 'P479S', 'N440K', 'V367F', 'N439K', 'K356R', 'G476S', 'L452R', 'A419S', 'N354T', 'R346S', 'T478K', 'D427N', 'Y505H', 'R346I', 'G496S', 'G446S', 'R346T', 'T376A', 'V483F', 'K417T', 'T376I', 'N501T', 'L452M', 'R408I', 'N460S', 'D427V', 'R346K', 'G339H', 'G446V', 'S371F', 'Q414R', 'P463S', 'N501Y', 'P479L', 'S494P', 'S375F', 'K417N', 'A411S', 'A522P', 'F490S', 'A520S', 'R357K', 'E484K', 'S477I', 'S459F', 'G339N', 'V382L', 'A344S', 'Y453F', 'G339D', 'A352S', 'N460K', 'L452Q', 'E484A', 'P384L', 'A522S', 'V367L', 'Q498R', 'N354K', 'Q493R', 'L455F', 'S477N', 'A475V', 'Q414K', 'A522V']\n",
      "['D405N', 'E484R', 'T385I', 'S373P', 'K444T', 'F490L', 'S371L', 'A348S', 'F486V', 'S371Y', 'R408S', 'E484Q', 'V445P', 'K444R', 'N450D', 'S494L', 'P479S', 'N440K', 'V367F', 'N439K', 'G446D', 'K356R', 'G476S', 'V445A', 'L452R', 'A419S', 'N354T', 'R346S', 'K444M', 'T478K', 'D427N', 'Y505H', 'R346I', 'G496S', 'G446S', 'R346T', 'F486P', 'K444N', 'T376A', 'V483F', 'K417T', 'T376I', 'N501T', 'L452M', 'R408I', 'N460S', 'D427V', 'R346K', 'G339H', 'G446V', 'S371F', 'Q414R', 'P463S', 'N501Y', 'P479L', 'S494P', 'F486A', 'S375F', 'K417N', 'A411S', 'A522P', 'F490S', 'A520S', 'R357K', 'E484K', 'S477I', 'S459F', 'G339N', 'V382L', 'A344S', 'F486S', 'Y453F', 'G339D', 'F486I', 'K356T', 'A352S', 'N460K', 'L452Q', 'E484A', 'P384L', 'A522S', 'V367L', 'Q498R', 'N354K', 'Q493R', 'L455F', 'S477N', 'A475V', 'L368I', 'Q414K', 'A522V']\n"
     ]
    }
   ],
   "source": [
    "for index, row in detailed_results_df.iterrows():\n",
    "    print(list(row['mutations_observed']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED = \"esm3_coord\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings of shape torch.Size([3803, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VIRAL\\plots\\../src\\utils.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path)  # Load the tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3122, 5)\n"
     ]
    }
   ],
   "source": [
    "df, train_x, train_y, targets = load_and_preprocess_data(EMBED)\n",
    "pheno_columns = [\n",
    "    \"delta_log_kd_ACE2\",\n",
    "    \"delta_log_kd_LY-CoV016\",\n",
    "    \"delta_log_kd_REGN10987\",\n",
    "    \"delta_log_kd_LY-CoV555\",\n",
    "    \"delta_log_kd_S309\",\n",
    "]\n",
    "pheno = df[pheno_columns]\n",
    "pheno = pheno.to_numpy()\n",
    "print(pheno.shape)\n",
    "\n",
    "fitnesses = bio_model(pheno)\n",
    "train_y = torch.tensor(\n",
    "    np.array([fitnesses, fitnesses, fitnesses, fitnesses, fitnesses]).transpose()\n",
    ")\n",
    "\n",
    "dataset = Dataset_perso(train_x, train_y)\n",
    "site_rbd_list = np.unique(df[\"site_SARS2\"].values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 mutation indexes: [3030, 1956, 555]\n",
      "3\n",
      "Row 1 mutation indexes: [1411, 2362, 1956, 1732, 555, 1713, 1946, 2730, 3030, 388, 3068, 2629, 2727, 2472]\n",
      "14\n",
      "Row 2 mutation indexes: [1956, 1946, 2730, 223, 1945, 2629, 2378, 1544, 1411, 3068, 2574, 2477, 1416, 3030, 388, 2727, 2472, 2362, 2329, 1732, 555, 1713, 217]\n",
      "23\n",
      "Row 3 mutation indexes: [826, 185, 1956, 97, 1376, 881, 318, 1946, 1453, 2730, 2118, 357, 677, 223, 2398, 1945, 2629, 2378, 2465, 707, 1544, 1411, 2775, 1339, 864, 216, 2568, 636, 2650, 1833, 3068, 2574, 560, 261, 2668, 350, 2611, 2450, 2477, 1416, 3030, 729, 388, 2346, 2727, 2472, 2626, 1975, 2362, 2403, 2358, 2329, 1732, 555, 1275, 1713, 2032, 2061, 1550, 374, 217, 1835, 1371, 3070]\n",
      "64\n",
      "Row 4 mutation indexes: [1221, 881, 677, 2568, 636, 261, 2519, 645, 1282, 2477, 1897, 2626, 2403, 1732, 555, 1713, 374, 2346, 1946, 1453, 357, 223, 2378, 1544, 2775, 216, 2650, 1833, 224, 722, 2450, 1416, 729, 2727, 1942, 1275, 2061, 1550, 217, 100, 1835, 631, 1376, 2118, 2730, 2398, 2629, 707, 1411, 1339, 3065, 2574, 3030, 388, 2472, 2358, 2032, 105, 826, 185, 1956, 97, 318, 2055, 1945, 2465, 864, 3068, 560, 2668, 350, 2611, 1975, 2362, 2329, 1371, 3070]\n",
      "77\n",
      "Row 5 mutation indexes: [1221, 2478, 881, 677, 1796, 2568, 636, 261, 2519, 645, 1282, 2477, 1812, 1794, 1897, 2626, 2403, 1732, 555, 1713, 1821, 374, 2346, 1800, 1946, 1453, 357, 223, 1790, 2378, 1544, 2775, 216, 2650, 1833, 224, 2514, 1791, 722, 2450, 1416, 729, 2727, 1942, 1275, 2061, 1550, 217, 100, 1835, 631, 1376, 2118, 2730, 2398, 2629, 2503, 707, 1411, 1339, 3065, 2574, 3030, 388, 2472, 2358, 2032, 105, 826, 185, 2517, 1956, 97, 2509, 376, 318, 2055, 1945, 2465, 864, 3068, 560, 2668, 350, 2611, 1975, 2362, 2329, 577, 1371, 3070]\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to find mutation encoding and indexes\n",
    "def get_mutation_indexes(detailed_df, site_mutation_df):\n",
    "    # Prepare a list to store the results\n",
    "    all_results = []\n",
    "\n",
    "    # Iterate over each row in detailed_results_df\n",
    "    for index, row in detailed_df.iterrows():\n",
    "        mutations = list(row[\"mutations_observed\"])\n",
    "        mutation_indexes = []\n",
    "\n",
    "        # Iterate through each mutation in the list\n",
    "        for mutation in mutations:\n",
    "            # Extract WT, site, and mutant from the mutation string (e.g., \"Y453F\")\n",
    "            wt = mutation[0]\n",
    "            site = float(mutation[1:-1])\n",
    "            mutant = mutation[-1]\n",
    "\n",
    "            # Find rows in the second dataframe matching mutant and site\n",
    "            matching_rows = site_mutation_df[\n",
    "                (site_mutation_df[\"mutation\"] == mutant) & (site_mutation_df[\"site_SARS2\"] == site)\n",
    "            ]\n",
    "\n",
    "            # Store the indexes of matching rows\n",
    "            mutation_indexes.extend(matching_rows.index.tolist())\n",
    "\n",
    "        # Append the result for the current row\n",
    "        all_results.append(mutation_indexes)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Call the function and print the results\n",
    "mutation_indexes_results = get_mutation_indexes(detailed_results_df, df)\n",
    "for i, indexes in enumerate(mutation_indexes_results):\n",
    "    print(f\"Row {i} mutation indexes: {indexes}\")\n",
    "    print(len(indexes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_indexes(active_learner, date_index):\n",
    "    train_data_u, _ = active_learner.train_dataset.get_data()\n",
    "\n",
    "    train_data_u_indexes = []\n",
    "    for j in range(len(df)):\n",
    "        for i in range(len(train_data_u)):\n",
    "            if df[EMBED][j] == train_data_u[i].tolist():\n",
    "                train_data_u_indexes.append(j)\n",
    "\n",
    "    print(\"indexes checked by embedding\", train_data_u_indexes)\n",
    "\n",
    "    training_set = df.loc[train_data_u_indexes]\n",
    "    # save training set in csv with name training_set_+strategy+\"_run_\"+run\n",
    "    filename = \"../script_results/1_batch_real_direct_esm3_coord/training_set_bloom_1000_date\"+str(date_index)+\".csv\"\n",
    "\n",
    "    # Save the training set to a CSV file\n",
    "    training_set.to_csv(filename, index=False)\n",
    "\n",
    "    hist_indexes = active_learner.get_training_indices_history()\n",
    "    # save as a npy with the right name\n",
    "    # Save the history as a .npy file\n",
    "    print(\"hist_indexes\", hist_indexes)\n",
    "    filename = \"../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date\"+str(date_index)+\".csv\"\n",
    "\n",
    "    # Save list of lists to a CSV file\n",
    "    with open(filename, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(hist_indexes)\n",
    "\n",
    "    print(f\"List of lists saved as CSV to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VIRAL\\plots\\../src\\utils.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(file_path)  # Load the tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings of shape torch.Size([3803, 1536])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_kd = pd.read_csv(\"../data_bloom/kd_bloom/df_bloom_processed.csv\")\n",
    "# rename columns site as site_SARS2\n",
    "df_kd.rename(columns={\"site\": \"site_SARS2\"}, inplace=True)\n",
    "\n",
    "\n",
    "train_data = load_esm_embeddings(\"esm3_coord\")\n",
    "\n",
    "\n",
    "targets = [\n",
    "    \"delta_log_kd_ACE2\",\n",
    "    \"delta_log_kd_LY-CoV016\",\n",
    "    \"delta_log_kd_REGN10987\",\n",
    "    \"delta_log_kd_LY-CoV555\",\n",
    "    \"delta_log_kd_S309\",\n",
    "]\n",
    "\n",
    "train_x = torch.tensor(train_data)\n",
    "train_y = torch.tensor(df_kd[targets].values)\n",
    "\n",
    "# Remove rows with NaN\n",
    "indexes_nan = np.unique(np.where(np.isnan(train_y))[0])\n",
    "non_nan_indexes = np.setdiff1d(np.arange(train_y.shape[0]), indexes_nan)\n",
    "\n",
    "train_x = train_x[non_nan_indexes]\n",
    "train_y = train_y[non_nan_indexes]\n",
    "df = df_kd.drop(indexes_nan).reset_index(drop=True)\n",
    "\n",
    "df[EMBED] = train_x.tolist()\n",
    "indexNames = []\n",
    "for i in range(len(df)):\n",
    "    if df[\"site_SARS2\"][i] in [331, 332, 333, 527, 528, 529, 530, 531]:\n",
    "        indexNames.append(i)\n",
    "df.drop(indexNames, inplace=True)\n",
    "#reset index\n",
    "df = df.reset_index(drop=True)\n",
    "train_x = np.delete(train_x, indexNames, axis=0)\n",
    "train_y = np.delete(train_y, indexNames, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new AL object\n",
      "training on  3  points\n",
      "Learned kernel: RationalQuadratic(alpha=1.32e+03, length_scale=592)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.00336, length_scale=311)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.77694360799343, P: 0.33226837060702874, Var: 1.1830344200134277\n",
      "indexes checked by embedding [10, 38, 39, 40, 42, 43, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 86, 87, 88, 89, 90, 91, 92, 114, 115, 117, 120, 122, 123, 125, 129, 130, 135, 138, 139, 144, 148, 152, 153, 154, 156, 162, 163, 166, 209, 214, 216, 218, 225, 232, 253, 270, 271, 273, 282, 283, 292, 325, 326, 328, 361, 362, 365, 366, 368, 369, 372, 377, 385, 396, 399, 400, 401, 402, 404, 405, 406, 409, 410, 411, 412, 413, 414, 416, 418, 422, 423, 434, 437, 438, 444, 446, 452, 453, 456, 457, 458, 459, 460, 461, 462, 463, 464, 466, 467, 468, 469, 470, 472, 473, 474, 480, 513, 514, 515, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 539, 541, 547, 548, 555, 570, 571, 572, 573, 575, 576, 578, 580, 581, 582, 583, 584, 585, 586, 588, 589, 590, 591, 594, 596, 601, 604, 605, 606, 608, 613, 623, 624, 627, 643, 686, 687, 688, 698, 699, 700, 703, 708, 710, 727, 741, 743, 744, 745, 747, 751, 752, 755, 756, 757, 760, 764, 765, 767, 768, 771, 774, 775, 776, 777, 778, 779, 780, 781, 782, 784, 791, 794, 796, 804, 807, 817, 819, 822, 828, 832, 836, 840, 841, 843, 845, 846, 851, 852, 855, 857, 858, 859, 860, 861, 862, 866, 870, 871, 872, 875, 890, 893, 900, 901, 904, 909, 912, 913, 914, 915, 917, 918, 920, 922, 923, 924, 925, 926, 927, 928, 930, 931, 938, 940, 947, 950, 956, 966, 974, 994, 996, 1004, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1016, 1017, 1019, 1020, 1021, 1022, 1023, 1026, 1031, 1050, 1052, 1066, 1069, 1075, 1079, 1083, 1084, 1085, 1086, 1088, 1090, 1092, 1093, 1094, 1095, 1096, 1097, 1099, 1100, 1103, 1104, 1105, 1106, 1108, 1109, 1112, 1113, 1116, 1121, 1123, 1125, 1132, 1156, 1157, 1160, 1164, 1167, 1171, 1172, 1177, 1180, 1189, 1190, 1196, 1198, 1200, 1208, 1233, 1236, 1241, 1245, 1246, 1253, 1254, 1260, 1275, 1277, 1284, 1292, 1294, 1308, 1309, 1311, 1316, 1319, 1344, 1350, 1352, 1355, 1359, 1360, 1365, 1372, 1406, 1440, 1480, 1498, 1501, 1513, 1515, 1517, 1518, 1520, 1521, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1538, 1540, 1549, 1550, 1553, 1557, 1564, 1568, 1569, 1572, 1573, 1574, 1575, 1576, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1596, 1612, 1613, 1615, 1616, 1622, 1625, 1627, 1631, 1634, 1640, 1650, 1652, 1654, 1657, 1660, 1661, 1664, 1671, 1672, 1674, 1683, 1725, 1740, 1743, 1745, 1764, 1765, 1766, 1769, 1771, 1772, 1778, 1779, 1788, 1797, 1862, 1864, 1866, 1867, 1869, 1873, 1876, 1878, 1879, 1881, 1883, 1884, 1885, 1887, 1888, 1889, 1892, 1893, 1895, 1899, 1902, 1904, 1911, 1956, 1959, 1961, 1962, 1969, 2010, 2013, 2014, 2016, 2017, 2018, 2024, 2025, 2028, 2035, 2037, 2044, 2069, 2083, 2085, 2092, 2093, 2100, 2101, 2109, 2111, 2113, 2114, 2119, 2120, 2123, 2129, 2134, 2139, 2142, 2143, 2144, 2145, 2146, 2148, 2150, 2151, 2152, 2153, 2155, 2157, 2158, 2159, 2160, 2161, 2166, 2170, 2177, 2178, 2199, 2203, 2206, 2208, 2212, 2215, 2225, 2234, 2237, 2240, 2243, 2245, 2246, 2252, 2253, 2275, 2277, 2279, 2280, 2282, 2284, 2298, 2301, 2303, 2310, 2319, 2321, 2329, 2351, 2367, 2394, 2405, 2408, 2415, 2424, 2433, 2443, 2471, 2518, 2519, 2529, 2538, 2541, 2546, 2564, 2566, 2576, 2584, 2598, 2599, 2602, 2605, 2607, 2610, 2614, 2617, 2621, 2624, 2626, 2632, 2633, 2662, 2671, 2676, 2690, 2728, 2769, 2770, 2774, 2776, 2782, 2784, 2785, 2786, 2790, 2791, 2809, 2810, 2811, 2813, 2814, 2816, 2817, 2819, 2822, 2823, 2824, 2825, 2826, 2828, 2829, 2831, 2833, 2835, 2836, 2838, 2841, 2843, 2847, 2848, 2850, 2854, 2857, 2858, 2859, 2883, 2884, 2885, 2888, 2893, 2894, 2897, 2898, 2902, 2907, 2909, 2911, 2914, 2918, 2921, 2922, 2923, 2925, 2927, 2929, 2932, 2935, 2936, 2937, 2940, 2944, 2956, 2997, 3012, 3030, 3035, 3074]\n",
      "hist_indexes [[555, 1956, 3030], [2471, 2944, 1725, 1674, 1568, 901, 1026, 2109, 10, 2321, 2607, 1233, 2728, 791, 460, 804, 2566, 2621, 710, 1533, 1157, 940, 2085, 2144, 2246, 2160, 2632, 400, 2240, 1889, 1899, 1532, 780, 1309, 1116, 1869, 828, 88, 292, 2252, 1661, 782, 2083, 2610, 1527, 1797, 2134, 768, 2854, 2541, 1241, 2415, 418, 931, 1866, 271, 2014, 422, 794, 1196, 2598, 2114, 2170, 1534, 1352, 2408, 2279, 2605, 214, 423, 586, 1050, 2212, 2676, 396, 2858, 2518, 2671, 1740, 326, 1573, 2143, 1052, 747, 1549, 1253, 1480, 1873, 1097, 1530, 2841, 1513, 2119, 2909, 1294, 1888, 2237, 2351, 2024, 55, 2028, 774, 71, 405, 2690, 81, 2784, 3074, 1016, 2093, 2929, 1778, 270, 1884, 1501, 2177, 938, 1867, 328, 2120, 1440, 75, 1121, 1862, 53, 900, 2822, 956, 2100, 2662, 406, 1962, 1745, 1108, 1743, 2626, 1518, 1521, 698, 1616, 947, 519, 775, 2151, 1316, 1292, 89, 1112, 1132, 1277, 438, 872, 1531, 777, 1578, 1564, 1625, 1023, 1772, 778, 2203, 368, 1622, 225, 59, 1557, 861, 52, 474, 1683, 139, 2614, 1012, 2791, 700, 2932, 283, 2519, 890, 573, 623, 624, 470, 2617, 1156, 893, 1579, 2275, 2790, 38, 1319, 2782, 461, 627, 3012, 2835, 858, 1671, 70, 416, 3035, 1372, 1172, 862, 48, 588, 92, 1895, 2850, 2443, 1160, 2284, 807, 209, 687, 2836, 144, 218, 153, 2433, 2599, 2225, 859, 2329, 1788, 1887, 91, 2922, 840, 434, 1094, 928, 613, 1879, 154, 1864, 2546, 54, 2234, 2529, 1885, 846, 1660, 365, 148, 1657, 2776, 2155, 1406, 996, 2013, 1180, 2564, 1190, 411, 1596, 2069, 1581, 63, 362, 601, 480, 756, 2018, 456, 2277, 2178, 930, 2157, 2997, 2833, 129, 369, 2893, 751, 1245, 1766, 2911, 2584, 2298, 1640, 1086, 2769, 699, 135, 1123, 1904, 1769, 2113, 2199, 361, 2918, 703, 767, 459, 1275, 1892, 904, 925, 125, 468, 67, 1355, 1765, 1167, 1575, 2282, 1260, 2843, 522, 1200, 2044, 253, 1969, 2914, 855, 2770, 2819, 2208, 2576, 1515, 2319, 1104, 2538, 1109, 817, 1359, 123, 1538, 1550, 596, 2310, 547, 1031, 377, 2927, 708, 2146, 1008, 832, 2129, 1007, 282, 2123, 1208, 216, 1779, 1771, 399, 78, 1177, 2394, 1164, 1961, 1672, 974, 2785, 46, 42, 1099, 152, 2245, 2367, 2111, 1106, 273, 523, 464, 1652, 1498, 1650, 166, 2848, 539, 920, 532, 2817, 1198, 845, 2161, 1540, 857, 755, 2921, 582, 1878, 851, 1189, 1529, 2936, 457, 923, 2280, 2301, 2602, 2825, 870, 43, 2935, 2142, 1020, 1569, 2940, 1902, 871, 994, 2017, 2829, 2923, 1553, 162, 1079, 1125, 1096, 2303, 1627, 1583, 2010, 2405, 1580, 114, 1090, 1092, 604, 1634, 950, 446, 473, 325, 578, 781, 74, 583, 581, 796, 875, 2139, 2037, 1344, 1764, 39, 541, 757, 1911, 1613, 1582, 727, 1013, 117, 608, 2153, 472, 760, 462, 2424, 2243, 64, 372, 72, 2774, 2956, 744, 2823, 590, 771, 1113, 163, 2816, 1019, 2884, 591, 909, 1959, 525, 866, 836, 466, 2898, 66, 2159, 458, 77, 2786, 2859, 1284, 2035, 1588, 819, 1004, 452, 605, 2633, 2813, 2902, 784, 2166, 2206, 776, 779, 924, 1584, 2092, 86, 1084, 444, 1585, 1517, 2814, 686, 73, 1311, 643, 1631, 62, 966, 1664, 58, 2624, 2145, 1093, 1881, 2885, 414, 1574, 2253, 2857, 87, 1100, 1022, 232, 2152, 463, 841, 2810, 1883, 2101, 2016, 2937, 764, 61, 1365, 76, 467, 927, 2150, 1171, 57, 1612, 1350, 1893, 2025, 1654, 1587, 576, 409, 527, 1586, 1876, 385, 2826, 402, 1254, 2148, 688, 2811, 115, 1021, 469, 90, 1246, 50, 1236, 918, 913, 1085, 1360, 437, 860, 40, 2824, 1520, 1308, 453, 410, 1103, 572, 585, 2828, 2809, 1572, 743, 2158, 122, 412, 912, 548, 521, 524, 571, 45, 1069, 843, 2907, 413, 51, 752, 520, 1075, 915, 822, 2215, 589, 120, 516, 1105, 606, 765, 1615, 926, 130, 404, 1095, 1017, 526, 530, 529, 594, 514, 515, 2925, 1083, 852, 2847, 2838, 741, 138, 580, 2883, 570, 80, 1011, 2894, 1010, 528, 922, 518, 1066, 513, 745, 366, 2897, 1576, 1088, 401, 156, 917, 584, 2831, 914, 2888, 1009, 575]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date0.csv\n",
      "created new AL object\n",
      "training on  14  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.000891, length_scale=1e-05)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned kernel: RationalQuadratic(alpha=0.0007, length_scale=26.8)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.5890523770417009, P: 0.16613418530351437, Var: 0.5326253175735474\n",
      "indexes checked by embedding [2, 3, 5, 11, 12, 14, 15, 29, 30, 31, 34, 35, 78, 79, 84, 88, 94, 97, 105, 106, 110, 116, 136, 140, 142, 160, 172, 173, 182, 183, 186, 201, 202, 203, 205, 221, 222, 228, 230, 231, 238, 239, 240, 243, 244, 246, 248, 249, 261, 262, 266, 268, 269, 271, 277, 278, 279, 281, 285, 287, 288, 289, 290, 291, 292, 295, 296, 297, 298, 301, 302, 303, 305, 306, 312, 314, 315, 316, 318, 319, 320, 326, 342, 344, 345, 354, 357, 358, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 388, 392, 420, 421, 429, 430, 431, 433, 439, 482, 486, 487, 491, 495, 496, 498, 505, 506, 508, 509, 543, 545, 547, 551, 553, 555, 560, 562, 563, 564, 567, 593, 642, 657, 661, 665, 667, 668, 670, 676, 678, 680, 692, 703, 705, 706, 714, 715, 716, 718, 719, 722, 724, 725, 731, 735, 738, 740, 759, 760, 762, 763, 765, 766, 767, 768, 770, 771, 772, 773, 774, 775, 776, 778, 781, 783, 798, 800, 801, 808, 809, 810, 812, 813, 817, 820, 821, 835, 838, 847, 848, 876, 898, 903, 905, 906, 908, 919, 981, 984, 1025, 1028, 1029, 1039, 1047, 1048, 1056, 1057, 1060, 1071, 1085, 1116, 1118, 1119, 1121, 1129, 1135, 1137, 1138, 1142, 1148, 1150, 1151, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1194, 1203, 1252, 1265, 1289, 1290, 1314, 1315, 1322, 1326, 1327, 1329, 1337, 1393, 1394, 1401, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1428, 1431, 1432, 1434, 1435, 1436, 1440, 1443, 1479, 1480, 1481, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1519, 1522, 1526, 1590, 1593, 1603, 1645, 1669, 1670, 1678, 1686, 1688, 1689, 1691, 1699, 1701, 1707, 1713, 1726, 1732, 1735, 1746, 1750, 1754, 1755, 1759, 1762, 1764, 1765, 1767, 1773, 1774, 1775, 1777, 1781, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1799, 1802, 1805, 1807, 1809, 1811, 1812, 1813, 1816, 1819, 1829, 1830, 1840, 1848, 1849, 1857, 1859, 1860, 1871, 1872, 1880, 1897, 1900, 1907, 1909, 1910, 1916, 1917, 1918, 1921, 1932, 1933, 1935, 1936, 1937, 1940, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1951, 1954, 1955, 1956, 1970, 1973, 1974, 1978, 1982, 1986, 1987, 1990, 1992, 1993, 1998, 2001, 2002, 2005, 2008, 2009, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2027, 2030, 2039, 2040, 2041, 2043, 2044, 2049, 2050, 2058, 2059, 2062, 2066, 2068, 2069, 2070, 2076, 2077, 2078, 2080, 2081, 2082, 2084, 2085, 2090, 2095, 2096, 2097, 2099, 2100, 2106, 2107, 2125, 2131, 2141, 2144, 2161, 2163, 2164, 2165, 2166, 2167, 2168, 2170, 2172, 2173, 2174, 2175, 2176, 2177, 2179, 2182, 2184, 2188, 2190, 2191, 2196, 2201, 2210, 2214, 2218, 2220, 2229, 2230, 2231, 2239, 2267, 2271, 2275, 2277, 2278, 2279, 2287, 2288, 2291, 2292, 2296, 2297, 2306, 2314, 2315, 2324, 2325, 2327, 2328, 2329, 2334, 2356, 2362, 2363, 2366, 2370, 2372, 2381, 2382, 2383, 2385, 2410, 2419, 2420, 2429, 2437, 2438, 2453, 2458, 2459, 2462, 2467, 2472, 2486, 2494, 2495, 2505, 2509, 2511, 2514, 2515, 2519, 2521, 2524, 2525, 2527, 2534, 2545, 2553, 2560, 2568, 2570, 2571, 2572, 2574, 2575, 2578, 2581, 2582, 2583, 2589, 2591, 2595, 2597, 2617, 2622, 2628, 2629, 2630, 2632, 2636, 2638, 2646, 2647, 2650, 2651, 2657, 2658, 2666, 2704, 2712, 2714, 2715, 2716, 2724, 2726, 2727, 2728, 2730, 2733, 2734, 2738, 2740, 2742, 2743, 2744, 2747, 2750, 2752, 2753, 2760, 2761, 2762, 2771, 2773, 2830, 2871, 2904, 2905, 2913, 2915, 2917, 2942, 2961, 2970, 2974, 2980, 2982, 2985, 2988, 2990, 2994, 3008, 3009, 3017, 3018, 3020, 3028, 3030, 3031, 3055, 3056, 3058, 3064, 3065, 3066, 3068, 3069, 3070, 3073, 3074, 3075, 3077, 3081, 3114]\n",
      "hist_indexes [[388, 555, 1411, 1713, 1732, 1946, 1956, 2362, 2472, 2629, 2727, 2730, 3030, 3068], [498, 1848, 2291, 3018, 1025, 2329, 2570, 906, 358, 2218, 228, 642, 2420, 3074, 2410, 740, 1943, 318, 2100, 2044, 1754, 1645, 919, 203, 1805, 2271, 3009, 1085, 2267, 1982, 486, 2734, 2287, 551, 1790, 1056, 342, 2982, 1910, 1998, 2753, 1699, 668, 244, 506, 142, 1519, 781, 110, 2016, 759, 2005, 2575, 714, 508, 810, 2773, 3066, 1489, 1443, 984, 1194, 2771, 2296, 2382, 1921, 2002, 2574, 1816, 798, 3073, 731, 1522, 1940, 981, 2385, 1322, 182, 1750, 14, 491, 1315, 1434, 2099, 817, 1493, 243, 898, 1764, 2090, 835, 392, 1494, 676, 908, 2494, 1337, 2, 1440, 2545, 562, 1071, 1849, 2324, 2560, 1678, 2595, 3008, 1526, 2628, 295, 1148, 2141, 1909, 1990, 2650, 1860, 2704, 2429, 2728, 1954, 1039, 2210, 1150, 1116, 2636, 2080, 2066, 2191, 2190, 303, 2961, 2167, 3070, 1488, 2486, 1774, 1121, 560, 326, 2184, 291, 2458, 2505, 1819, 2519, 29, 2521, 378, 5, 205, 240, 1829, 1872, 1947, 482, 222, 593, 140, 505, 2744, 105, 88, 1490, 547, 2658, 1418, 2372, 2572, 290, 665, 1773, 719, 249, 820, 2651, 2370, 2144, 1691, 3064, 277, 34, 661, 2107, 813, 239, 2327, 2980, 3075, 2220, 1970, 3077, 2762, 2747, 1813, 1428, 2085, 1973, 3081, 1840, 2589, 2726, 2515, 2646, 2459, 1935, 2534, 3114, 2712, 703, 1830, 221, 1765, 2438, 821, 2527, 2988, 319, 1775, 1486, 3058, 2062, 285, 2182, 2871, 722, 1802, 1029, 1432, 2970, 1048, 1701, 370, 3028, 2591, 1431, 496, 1746, 1986, 2231, 495, 2059, 509, 1135, 2553, 183, 312, 838, 1686, 2328, 1871, 1857, 1933, 2462, 2742, 2275, 1420, 735, 2383, 160, 314, 316, 366, 1900, 2164, 1807, 186, 1811, 2525, 15, 1951, 1203, 279, 1265, 771, 1590, 1393, 1252, 2325, 1314, 238, 431, 765, 2381, 2716, 2001, 261, 1329, 2942, 1955, 116, 1060, 262, 1907, 1118, 1880, 306, 1784, 11, 715, 1175, 1670, 2196, 2750, 1190, 2082, 3056, 35, 2279, 692, 1948, 78, 567, 3055, 3020, 2306, 1129, 725, 2015, 2583, 1603, 320, 553, 1028, 2188, 429, 2738, 2994, 670, 2715, 3, 2974, 301, 1987, 809, 2166, 2657, 2913, 1498, 271, 3031, 1949, 1176, 2632, 173, 2666, 1593, 1481, 1142, 2297, 1788, 564, 3069, 2990, 2070, 2292, 136, 1787, 1137, 1936, 848, 1932, 2084, 1974, 2760, 357, 1513, 2985, 766, 2239, 1436, 778, 2027, 2214, 2453, 79, 2733, 738, 2163, 289, 2013, 2022, 706, 1785, 2740, 1799, 563, 1735, 1057, 3017, 84, 2915, 2025, 1993, 296, 487, 1809, 801, 767, 680, 2168, 2170, 2509, 2366, 281, 172, 903, 2724, 2131, 354, 763, 1978, 2106, 230, 1786, 1499, 30, 2008, 2179, 31, 363, 2229, 1944, 2095, 1689, 297, 2161, 2076, 2081, 246, 783, 2581, 1759, 94, 762, 545, 201, 1394, 678, 2597, 2495, 2125, 2288, 2315, 2314, 439, 2568, 2467, 2017, 2571, 876, 302, 1138, 1327, 2356, 292, 2058, 2630, 905, 364, 367, 298, 1726, 2904, 1480, 1945, 1180, 2617, 2077, 2165, 2039, 1783, 2177, 1916, 812, 2511, 2277, 718, 12, 1992, 2830, 1435, 667, 808, 768, 2334, 1917, 248, 2201, 724, 1918, 231, 1119, 2050, 543, 2230, 2069, 1422, 2419, 372, 266, 1479, 657, 1179, 2068, 2638, 2030, 2582, 315, 2622, 1755, 1789, 2917, 2278, 1767, 773, 345, 705, 2905, 2514, 1151, 1189, 2743, 1777, 1897, 1183, 1781, 2172, 2175, 2761, 1502, 433, 2437, 1326, 2173, 2752, 2578, 2043, 847, 97, 1762, 1047, 2176, 1177, 1688, 1937, 1423, 1289, 2096, 421, 774, 2049, 379, 202, 305, 2041, 1509, 716, 1191, 1795, 1410, 1500, 2012, 365, 776, 106, 269, 1405, 1794, 2363, 430, 2097, 1290, 369, 2078, 1406, 760, 1501, 2714, 1797, 2174, 1419, 1793, 1505, 374, 1182, 2011, 1707, 368, 2647, 1514, 287, 1792, 1503, 268, 420, 1504, 288, 1414, 1187, 2040, 800, 1408, 1407, 1859, 1178, 1796, 2014, 1185, 377, 1510, 1403, 3065, 361, 1812, 2009, 2524, 1791, 1669, 775, 1409, 1186, 375, 371, 1184, 2024, 1417, 1496, 2021, 376, 1512, 344, 2023, 1173, 772, 1188, 2019, 1404, 1507, 278, 770, 373, 1415, 1511, 2020, 1508, 1401, 1416, 1506, 1412, 1413]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date1.csv\n",
      "created new AL object\n",
      "training on  23  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.00695, length_scale=69.2)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.000843, length_scale=14.3)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.5956553973902728, P: 0.17252396166134185, Var: 0.5676282048225403\n",
      "indexes checked by embedding [0, 5, 11, 12, 15, 19, 24, 29, 30, 31, 33, 34, 35, 76, 78, 79, 84, 86, 88, 91, 94, 95, 97, 105, 106, 107, 109, 110, 116, 126, 136, 142, 146, 160, 202, 205, 217, 221, 222, 223, 228, 230, 231, 236, 238, 239, 240, 242, 244, 245, 266, 268, 269, 271, 278, 279, 285, 287, 288, 289, 290, 291, 292, 296, 297, 298, 300, 301, 302, 303, 305, 314, 315, 316, 342, 344, 345, 347, 353, 354, 357, 361, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 378, 379, 388, 392, 393, 407, 415, 420, 430, 433, 448, 486, 487, 488, 491, 498, 505, 524, 545, 547, 551, 555, 556, 562, 563, 564, 566, 567, 589, 598, 600, 602, 605, 620, 657, 660, 661, 678, 680, 690, 692, 703, 715, 716, 718, 722, 724, 734, 735, 738, 747, 749, 753, 756, 757, 760, 766, 767, 768, 770, 771, 772, 773, 774, 775, 776, 778, 781, 783, 795, 798, 800, 801, 803, 804, 808, 809, 810, 812, 813, 814, 817, 821, 829, 835, 847, 848, 874, 905, 916, 954, 960, 961, 962, 964, 965, 969, 981, 984, 1015, 1023, 1025, 1026, 1047, 1050, 1056, 1057, 1059, 1060, 1064, 1085, 1086, 1099, 1116, 1118, 1119, 1121, 1135, 1137, 1138, 1142, 1146, 1147, 1148, 1150, 1151, 1170, 1173, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1203, 1249, 1252, 1265, 1281, 1289, 1290, 1306, 1310, 1314, 1321, 1322, 1394, 1401, 1403, 1404, 1406, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1420, 1422, 1423, 1425, 1428, 1431, 1432, 1434, 1435, 1436, 1479, 1480, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1526, 1544, 1545, 1549, 1563, 1580, 1584, 1587, 1603, 1610, 1645, 1669, 1678, 1688, 1689, 1691, 1699, 1707, 1713, 1726, 1732, 1735, 1743, 1754, 1755, 1758, 1759, 1762, 1767, 1774, 1775, 1777, 1778, 1781, 1789, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1800, 1812, 1815, 1816, 1819, 1829, 1830, 1833, 1834, 1849, 1857, 1859, 1868, 1869, 1871, 1873, 1880, 1887, 1888, 1891, 1892, 1893, 1897, 1900, 1906, 1907, 1909, 1910, 1916, 1917, 1918, 1923, 1930, 1932, 1933, 1937, 1938, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1951, 1954, 1955, 1956, 1959, 1961, 1964, 1968, 1969, 1970, 1982, 1986, 1987, 1990, 1992, 1993, 1994, 1998, 2001, 2002, 2005, 2006, 2008, 2009, 2011, 2014, 2015, 2017, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2040, 2041, 2043, 2047, 2049, 2050, 2056, 2058, 2059, 2062, 2063, 2066, 2068, 2069, 2070, 2071, 2076, 2077, 2078, 2080, 2081, 2082, 2083, 2084, 2096, 2097, 2104, 2106, 2123, 2125, 2127, 2131, 2133, 2134, 2138, 2144, 2154, 2161, 2165, 2166, 2167, 2168, 2170, 2172, 2173, 2174, 2175, 2176, 2177, 2179, 2180, 2182, 2184, 2185, 2188, 2190, 2191, 2192, 2194, 2195, 2196, 2214, 2230, 2239, 2247, 2248, 2249, 2256, 2267, 2271, 2272, 2275, 2277, 2278, 2279, 2284, 2286, 2287, 2288, 2291, 2292, 2294, 2306, 2324, 2327, 2328, 2329, 2332, 2334, 2346, 2362, 2363, 2370, 2378, 2382, 2383, 2419, 2420, 2437, 2438, 2446, 2458, 2459, 2462, 2465, 2467, 2468, 2469, 2471, 2472, 2473, 2475, 2476, 2477, 2479, 2480, 2481, 2483, 2486, 2495, 2503, 2505, 2509, 2511, 2513, 2514, 2515, 2517, 2518, 2519, 2521, 2522, 2524, 2527, 2534, 2553, 2554, 2560, 2562, 2564, 2566, 2568, 2570, 2571, 2572, 2574, 2575, 2576, 2578, 2579, 2581, 2582, 2584, 2589, 2590, 2591, 2593, 2594, 2595, 2597, 2617, 2622, 2628, 2629, 2630, 2632, 2636, 2638, 2646, 2647, 2650, 2651, 2712, 2714, 2723, 2724, 2726, 2727, 2728, 2730, 2731, 2733, 2740, 2742, 2743, 2744, 2747, 2750, 2752, 2760, 2761, 2762, 2764, 2766, 2769, 2771, 2772, 2774, 2778, 2780, 2781, 2782, 2784, 2812, 2829, 2830, 2837, 2839, 2871, 2887, 2899, 2902, 2905, 2915, 2917, 2929, 2942, 2950, 2951, 2952, 2954, 2970, 2974, 2978, 2988, 2990, 2991, 2992, 2993, 2994, 3020, 3027, 3030, 3031, 3065, 3068, 3073, 3081, 3114, 3117]\n",
      "hist_indexes [[217, 223, 388, 555, 1411, 1416, 1544, 1713, 1732, 1945, 1946, 1956, 2329, 2362, 2378, 2472, 2477, 2574, 2629, 2727, 2730, 3030, 3068], [2214, 2595, 146, 242, 2766, 1689, 240, 15, 420, 2812, 279, 803, 1406, 2056, 2899, 1897, 1026, 2521, 2486, 2332, 1176, 847, 300, 76, 314, 2025, 1281, 1869, 2650, 678, 2929, 353, 3027, 1025, 2584, 1923, 1789, 2248, 1023, 1490, 690, 969, 1781, 2247, 1499, 2646, 1498, 1175, 2104, 107, 1970, 3031, 1774, 1954, 1494, 378, 1987, 2829, 448, 660, 2127, 205, 0, 1064, 1118, 1310, 1959, 2628, 2871, 1778, 661, 2638, 1142, 1086, 1584, 1322, 1050, 874, 289, 2744, 1645, 301, 1775, 1015, 778, 2015, 781, 2772, 2179, 86, 11, 244, 2778, 2138, 2742, 556, 347, 680, 486, 1170, 1873, 2382, 753, 2070, 2294, 1819, 1891, 2017, 2286, 734, 1795, 620, 524, 1893, 2887, 5, 1415, 305, 1488, 2723, 738, 598, 814, 1119, 1549, 366, 2902, 2083, 2905, 236, 1489, 24, 1099, 1587, 829, 1834, 2837, 393, 795, 1249, 1252, 2636, 1190, 105, 2011, 1425, 2446, 2784, 271, 2651, 735, 2002, 724, 1815, 2192, 905, 1726, 1791, 269, 245, 2306, 1306, 1949, 415, 1743, 2527, 1930, 2185, 1943, 3117, 703, 2327, 2830, 767, 1321, 2522, 2271, 1955, 1998, 2728, 1180, 1754, 1969, 2096, 2168, 1085, 1880, 1203, 2726, 2272, 91, 1580, 2495, 1408, 2774, 2839, 2167, 2346, 1900, 1060, 1907, 1515, 2534, 2097, 2974, 954, 363, 804, 1868, 95, 1951, 1121, 3073, 1610, 1982, 316, 2165, 2066, 2084, 2780, 1906, 835, 2125, 1830, 2106, 1403, 2781, 589, 2562, 2467, 1968, 498, 1290, 562, 1964, 2050, 2047, 1691, 2080, 2370, 142, 2951, 1849, 2063, 505, 2752, 2182, 809, 2420, 605, 2731, 2166, 109, 2733, 747, 222, 1047, 1545, 1289, 1759, 291, 2762, 1116, 2071, 1699, 1833, 2462, 266, 1688, 136, 2747, 2256, 433, 1829, 2082, 1678, 798, 964, 2554, 2771, 3081, 1146, 2022, 1183, 238, 984, 2458, 407, 2180, 566, 757, 1918, 364, 2076, 2438, 916, 2764, 2970, 2566, 303, 2134, 1148, 2267, 2991, 268, 228, 3114, 392, 1486, 2194, 2123, 1961, 547, 290, 2184, 2383, 2915, 2769, 2170, 1794, 1932, 2782, 2014, 110, 2518, 1993, 1796, 292, 771, 981, 2712, 19, 2019, 2917, 1414, 961, 2279, 2324, 2133, 2334, 1493, 2505, 1916, 342, 768, 2239, 783, 718, 1417, 2172, 1189, 1758, 1480, 1800, 2471, 756, 2632, 2068, 2994, 2024, 12, 1938, 88, 1513, 801, 1191, 1986, 2291, 2195, 2062, 1871, 2191, 239, 817, 2740, 379, 2328, 491, 2287, 97, 848, 1479, 1797, 1735, 79, 1059, 1777, 1603, 230, 2503, 1526, 962, 1888, 231, 488, 716, 2284, 2553, 1892, 1917, 2459, 116, 3020, 1793, 749, 94, 1436, 345, 2954, 545, 2517, 1407, 296, 1933, 2993, 2950, 78, 2278, 2177, 1409, 2154, 2006, 1314, 2049, 2059, 960, 2724, 1994, 315, 1147, 1910, 810, 2363, 2009, 221, 2437, 2196, 1909, 1816, 1434, 2081, 1948, 1137, 2144, 965, 2023, 2069, 722, 1857, 2005, 2249, 821, 2578, 2277, 1056, 371, 1992, 2590, 770, 2043, 2161, 2622, 367, 2760, 1767, 84, 776, 2419, 774, 813, 2008, 766, 1138, 1179, 715, 1859, 1432, 1792, 2714, 2481, 1505, 1404, 368, 2594, 551, 2952, 1150, 657, 35, 1265, 2990, 2576, 357, 2292, 1057, 567, 773, 2176, 2519, 2230, 2582, 2593, 2589, 1394, 760, 1937, 160, 33, 812, 1887, 2597, 2581, 365, 2469, 2513, 600, 1431, 302, 2630, 29, 1177, 692, 2591, 2190, 1762, 298, 1990, 2041, 34, 1422, 374, 126, 202, 2021, 2978, 1435, 1509, 1413, 2988, 1428, 285, 564, 369, 2465, 1420, 1944, 1502, 3065, 2077, 2524, 2058, 297, 2288, 2992, 2750, 2761, 2617, 2483, 1182, 808, 1503, 1563, 2515, 2175, 372, 1151, 775, 1947, 1401, 1135, 2174, 2188, 1669, 1500, 1707, 377, 2743, 1423, 2575, 2647, 2001, 354, 2473, 2173, 375, 288, 1501, 1186, 30, 2509, 2131, 2078, 2568, 1514, 2942, 487, 602, 2275, 361, 2572, 2579, 2511, 344, 430, 106, 376, 2564, 800, 1184, 287, 2476, 563, 772, 1755, 2020, 2468, 1185, 31, 1187, 1504, 1512, 373, 1178, 1188, 2570, 1506, 1510, 1173, 2480, 1508, 2475, 1496, 2560, 2514, 2040, 2479, 1412, 1511, 1507, 278, 1812, 2571]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date2.csv\n",
      "created new AL object\n",
      "training on  64  points\n",
      "Learned kernel: RationalQuadratic(alpha=1e+05, length_scale=207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.000975, length_scale=53.5)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.6932646683091523, P: 0.25559105431309903, Var: 1.0099550485610962\n",
      "indexes checked by embedding [19, 32, 78, 79, 87, 88, 97, 108, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 145, 152, 154, 155, 160, 172, 185, 188, 204, 216, 217, 221, 223, 230, 231, 232, 247, 261, 268, 278, 287, 288, 290, 303, 318, 325, 344, 346, 347, 348, 350, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 388, 392, 395, 396, 399, 400, 401, 402, 403, 404, 410, 416, 448, 450, 487, 495, 497, 505, 512, 514, 546, 555, 560, 563, 570, 572, 573, 581, 584, 586, 587, 591, 621, 636, 659, 677, 707, 722, 727, 729, 734, 738, 741, 755, 756, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 774, 775, 776, 777, 778, 780, 781, 782, 791, 799, 800, 801, 813, 814, 817, 821, 826, 829, 835, 850, 857, 864, 881, 914, 916, 929, 930, 950, 951, 953, 954, 955, 956, 957, 958, 960, 961, 962, 963, 964, 965, 966, 973, 1007, 1018, 1056, 1069, 1076, 1095, 1101, 1103, 1105, 1116, 1118, 1119, 1120, 1121, 1127, 1128, 1133, 1134, 1135, 1136, 1137, 1138, 1140, 1146, 1147, 1150, 1154, 1156, 1159, 1165, 1168, 1171, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1194, 1228, 1251, 1252, 1261, 1275, 1289, 1290, 1306, 1307, 1308, 1309, 1311, 1314, 1315, 1317, 1320, 1321, 1329, 1336, 1339, 1342, 1355, 1363, 1365, 1367, 1368, 1371, 1375, 1376, 1377, 1381, 1401, 1411, 1412, 1416, 1420, 1422, 1423, 1425, 1431, 1434, 1435, 1440, 1453, 1479, 1482, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1520, 1526, 1529, 1530, 1533, 1537, 1542, 1544, 1545, 1549, 1550, 1566, 1568, 1572, 1574, 1583, 1603, 1610, 1612, 1613, 1615, 1622, 1631, 1632, 1652, 1669, 1691, 1698, 1707, 1713, 1732, 1737, 1764, 1765, 1767, 1771, 1774, 1808, 1812, 1814, 1826, 1830, 1832, 1833, 1835, 1857, 1861, 1862, 1863, 1868, 1871, 1873, 1875, 1887, 1888, 1893, 1900, 1903, 1908, 1909, 1910, 1916, 1917, 1919, 1932, 1937, 1938, 1939, 1945, 1946, 1950, 1951, 1954, 1956, 1959, 1964, 1968, 1969, 1975, 1991, 2001, 2013, 2014, 2017, 2019, 2020, 2024, 2032, 2049, 2056, 2061, 2063, 2064, 2066, 2067, 2068, 2069, 2071, 2073, 2076, 2077, 2078, 2080, 2081, 2082, 2084, 2091, 2106, 2118, 2134, 2142, 2143, 2144, 2145, 2146, 2147, 2149, 2150, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2165, 2166, 2168, 2170, 2172, 2173, 2175, 2176, 2177, 2178, 2179, 2184, 2188, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2261, 2267, 2271, 2275, 2276, 2277, 2278, 2280, 2282, 2284, 2287, 2288, 2290, 2291, 2292, 2294, 2295, 2298, 2309, 2311, 2312, 2324, 2329, 2333, 2346, 2358, 2362, 2365, 2369, 2378, 2398, 2403, 2412, 2414, 2415, 2417, 2419, 2421, 2424, 2425, 2426, 2450, 2460, 2465, 2466, 2468, 2469, 2470, 2472, 2473, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2503, 2509, 2510, 2511, 2514, 2516, 2518, 2522, 2523, 2526, 2527, 2529, 2531, 2533, 2538, 2539, 2540, 2553, 2559, 2560, 2564, 2568, 2570, 2571, 2574, 2579, 2580, 2581, 2582, 2584, 2585, 2589, 2590, 2591, 2593, 2594, 2595, 2598, 2602, 2603, 2605, 2606, 2607, 2610, 2611, 2612, 2614, 2616, 2617, 2621, 2622, 2624, 2626, 2629, 2633, 2634, 2635, 2647, 2650, 2660, 2664, 2666, 2667, 2668, 2669, 2673, 2712, 2726, 2727, 2728, 2730, 2764, 2775, 2781, 2790, 2791, 2793, 2802, 2805, 2806, 2809, 2810, 2812, 2826, 2828, 2829, 2831, 2845, 2847, 2849, 2850, 2854, 2857, 2866, 2867, 2869, 2871, 2883, 2887, 2890, 2899, 2902, 2904, 2905, 2906, 2907, 2909, 2911, 2914, 2918, 2922, 2923, 2924, 2925, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2986, 2989, 2991, 2992, 3020, 3030, 3068, 3070, 3074, 3075]\n",
      "hist_indexes [[97, 185, 216, 217, 223, 261, 318, 350, 357, 374, 388, 555, 560, 636, 677, 707, 729, 826, 864, 881, 1275, 1339, 1371, 1376, 1411, 1416, 1453, 1544, 1550, 1713, 1732, 1833, 1835, 1945, 1946, 1956, 1975, 2032, 2061, 2118, 2329, 2346, 2358, 2362, 2378, 2398, 2403, 2450, 2465, 2472, 2477, 2568, 2574, 2611, 2626, 2629, 2650, 2668, 2727, 2730, 2775, 3030, 3068, 3070], [1875, 1069, 1342, 400, 2271, 2531, 1549, 659, 1812, 1314, 2518, 152, 1146, 2712, 1830, 2564, 563, 586, 2425, 1893, 1194, 2241, 2170, 1909, 290, 2509, 278, 1871, 1315, 2284, 2369, 2466, 395, 2511, 2161, 1435, 930, 2184, 2256, 1329, 2591, 1968, 2585, 221, 1808, 1900, 2594, 755, 791, 3075, 1007, 817, 2158, 1537, 416, 1101, 1919, 1482, 2589, 2802, 2595, 2257, 396, 2291, 1603, 172, 2553, 2925, 2172, 2616, 1959, 1018, 2073, 1542, 960, 1228, 2001, 2066, 857, 2419, 2666, 2673, 1568, 2902, 2890, 2426, 2188, 325, 591, 2764, 835, 88, 1631, 813, 951, 19, 2831, 738, 514, 2414, 2017, 2580, 1954, 850, 133, 2278, 2986, 2290, 2503, 1991, 1533, 2056, 145, 2612, 1105, 2415, 1910, 780, 2523, 204, 399, 962, 914, 2924, 2922, 2421, 2091, 2288, 1412, 2049, 1861, 2475, 2365, 2992, 2179, 2076, 188, 756, 2267, 1765, 2084, 2417, 1691, 1863, 1887, 1056, 347, 2063, 1355, 2166, 1252, 2726, 2669, 973, 1479, 1261, 2324, 1566, 2781, 1136, 2728, 2244, 1363, 2527, 1771, 2176, 782, 2014, 1613, 2570, 2559, 2622, 2478, 1168, 1545, 2460, 2624, 1375, 232, 1939, 1530, 801, 2854, 2849, 1610, 1401, 1095, 2647, 1529, 3020, 814, 2013, 2249, 1367, 348, 2606, 1832, 953, 829, 1440, 116, 2560, 303, 1932, 2078, 2605, 1951, 268, 2603, 1368, 2134, 2633, 1857, 2024, 505, 2412, 1774, 961, 2907, 800, 1632, 2526, 2239, 2019, 2150, 2869, 1518, 587, 570, 1321, 1969, 2522, 2918, 1171, 2634, 2621, 581, 1615, 2309, 1814, 1764, 727, 108, 2168, 2080, 138, 2791, 2424, 1826, 2146, 403, 958, 2923, 741, 87, 2476, 2243, 2282, 2887, 2312, 1767, 2237, 1903, 2909, 1572, 2152, 1916, 955, 2261, 1862, 916, 2294, 2177, 2175, 2082, 2298, 799, 546, 929, 450, 2540, 2904, 1937, 584, 2571, 956, 2991, 2593, 1127, 821, 2295, 2510, 2952, 2660, 2064, 2470, 2245, 495, 1336, 769, 2157, 954, 512, 1320, 1888, 2810, 2806, 344, 2805, 2866, 359, 2480, 2664, 2539, 722, 2333, 1873, 32, 1186, 2311, 155, 123, 2867, 966, 2989, 1574, 2899, 2635, 1103, 1179, 2468, 2154, 2247, 362, 2144, 2584, 621, 2793, 2178, 2277, 1381, 1917, 2529, 2602, 160, 2533, 2106, 1183, 2871, 154, 1737, 247, 734, 2081, 1251, 1425, 2847, 1307, 1309, 1938, 1516, 2020, 2165, 2479, 2483, 2667, 2812, 1290, 401, 1120, 1908, 2826, 1698, 2252, 2156, 2143, 2292, 2173, 1150, 1116, 2598, 2582, 1317, 1583, 2473, 1515, 360, 2240, 1431, 2481, 1612, 763, 2538, 2514, 2617, 1434, 2254, 2614, 2607, 1076, 346, 2906, 1950, 1365, 2482, 964, 1135, 448, 2238, 1622, 1652, 487, 2255, 2845, 2829, 2071, 2280, 2153, 2911, 950, 573, 497, 2516, 1669, 2905, 136, 2790, 1176, 1156, 1191, 781, 367, 1134, 2883, 2077, 2251, 1180, 2957, 2276, 572, 1377, 2914, 1182, 3074, 1121, 1420, 1154, 404, 1964, 1175, 965, 402, 2142, 2579, 772, 2253, 370, 2287, 1165, 392, 1308, 2145, 2857, 765, 1188, 2149, 1184, 2469, 2590, 2946, 1306, 770, 2942, 1707, 1190, 1189, 2581, 1502, 2275, 2940, 1520, 1133, 2250, 1289, 371, 1185, 2160, 2944, 1517, 288, 2809, 2958, 1119, 2948, 231, 957, 775, 766, 2956, 115, 2610, 2068, 410, 2248, 2242, 1868, 2159, 1187, 1423, 2941, 2955, 762, 135, 2155, 2943, 2147, 129, 767, 777, 2069, 373, 117, 2950, 774, 118, 2945, 1526, 2850, 1311, 764, 760, 768, 1173, 1128, 1422, 2067, 369, 375, 79, 2828, 376, 776, 1174, 132, 287, 124, 230, 131, 2954, 368, 1177, 128, 366, 364, 120, 379, 2953, 1140, 78, 771, 778, 963, 377, 119, 122, 126, 1147, 1138, 1159, 1505, 378, 130, 1497, 1511, 114, 125, 2947, 2951, 1137, 1501, 1118, 1508, 1506, 1503, 361, 363, 1499, 1507, 1496, 1512, 1510, 1178, 1504, 1498, 372, 365, 1500, 1513, 1514, 121, 127]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date3.csv\n",
      "created new AL object\n",
      "training on  77  points\n",
      "Learned kernel: RationalQuadratic(alpha=1e+05, length_scale=213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.000665, length_scale=4.12)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.7055684825257779, P: 0.2715654952076677, Var: 0.8393190503120422\n",
      "indexes checked by embedding [11, 19, 24, 25, 32, 70, 72, 73, 75, 78, 79, 81, 88, 97, 100, 102, 105, 108, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 155, 160, 172, 175, 185, 188, 204, 216, 217, 223, 224, 230, 231, 232, 245, 247, 251, 261, 268, 271, 278, 285, 287, 288, 290, 297, 302, 303, 317, 318, 344, 345, 346, 347, 348, 350, 357, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 388, 392, 402, 404, 435, 448, 450, 479, 482, 487, 495, 496, 497, 498, 505, 511, 512, 540, 546, 547, 555, 560, 563, 573, 586, 587, 591, 621, 631, 636, 645, 651, 656, 657, 659, 677, 707, 710, 722, 729, 738, 758, 759, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 781, 797, 821, 826, 835, 850, 855, 864, 881, 916, 929, 950, 954, 955, 956, 957, 962, 963, 964, 965, 966, 968, 973, 976, 987, 1013, 1051, 1063, 1076, 1101, 1105, 1116, 1118, 1119, 1120, 1121, 1123, 1126, 1127, 1128, 1129, 1133, 1134, 1135, 1137, 1138, 1140, 1147, 1150, 1154, 1159, 1165, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1221, 1226, 1275, 1282, 1289, 1290, 1306, 1311, 1314, 1329, 1336, 1339, 1342, 1363, 1365, 1368, 1371, 1376, 1377, 1381, 1401, 1411, 1412, 1416, 1420, 1422, 1423, 1425, 1431, 1434, 1435, 1453, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1519, 1520, 1526, 1530, 1533, 1537, 1542, 1544, 1545, 1549, 1550, 1551, 1552, 1558, 1563, 1566, 1607, 1652, 1667, 1669, 1678, 1682, 1691, 1707, 1713, 1730, 1732, 1737, 1762, 1764, 1765, 1767, 1771, 1774, 1778, 1786, 1808, 1812, 1814, 1826, 1833, 1834, 1835, 1857, 1862, 1863, 1868, 1871, 1873, 1897, 1900, 1903, 1908, 1909, 1910, 1916, 1917, 1919, 1932, 1937, 1938, 1939, 1942, 1945, 1946, 1949, 1950, 1951, 1952, 1954, 1955, 1956, 1957, 1959, 1961, 1962, 1964, 1968, 1969, 1975, 1987, 1994, 2001, 2008, 2013, 2019, 2020, 2024, 2032, 2042, 2043, 2051, 2054, 2055, 2056, 2058, 2060, 2061, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2071, 2073, 2076, 2077, 2078, 2080, 2081, 2082, 2084, 2091, 2106, 2118, 2142, 2144, 2145, 2146, 2147, 2149, 2154, 2155, 2156, 2157, 2159, 2160, 2165, 2166, 2168, 2173, 2175, 2177, 2178, 2179, 2184, 2188, 2237, 2239, 2240, 2242, 2243, 2244, 2245, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2261, 2267, 2271, 2272, 2275, 2276, 2277, 2278, 2280, 2282, 2284, 2287, 2288, 2290, 2291, 2292, 2294, 2295, 2298, 2305, 2309, 2310, 2311, 2312, 2329, 2333, 2346, 2358, 2362, 2365, 2369, 2378, 2384, 2395, 2397, 2398, 2402, 2403, 2406, 2407, 2412, 2414, 2415, 2416, 2417, 2421, 2424, 2425, 2426, 2450, 2460, 2465, 2468, 2469, 2470, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2503, 2508, 2509, 2510, 2511, 2514, 2516, 2517, 2518, 2519, 2521, 2522, 2527, 2529, 2533, 2537, 2538, 2539, 2540, 2560, 2564, 2565, 2567, 2568, 2570, 2571, 2573, 2574, 2578, 2579, 2581, 2582, 2584, 2585, 2588, 2589, 2590, 2591, 2593, 2594, 2595, 2597, 2598, 2602, 2603, 2605, 2606, 2607, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2629, 2630, 2631, 2633, 2634, 2635, 2647, 2650, 2660, 2662, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2683, 2692, 2712, 2726, 2727, 2728, 2730, 2750, 2760, 2763, 2764, 2765, 2766, 2768, 2775, 2788, 2790, 2791, 2793, 2799, 2802, 2805, 2806, 2807, 2809, 2810, 2812, 2826, 2828, 2829, 2850, 2871, 2874, 2887, 2899, 2904, 2905, 2906, 2907, 2909, 2911, 2912, 2915, 2917, 2918, 2920, 2940, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2978, 2984, 2985, 2986, 2988, 2989, 2991, 2992, 2993, 2994, 3020, 3030, 3065, 3068, 3070, 3074, 3119]\n",
      "hist_indexes [[97, 100, 105, 185, 216, 217, 223, 224, 261, 318, 350, 357, 374, 388, 555, 560, 631, 636, 645, 677, 707, 722, 729, 826, 864, 881, 1221, 1275, 1282, 1339, 1371, 1376, 1411, 1416, 1453, 1544, 1550, 1713, 1732, 1833, 1835, 1897, 1942, 1945, 1946, 1956, 1975, 2032, 2055, 2061, 2118, 2329, 2346, 2358, 2362, 2378, 2398, 2403, 2450, 2465, 2472, 2477, 2519, 2568, 2574, 2611, 2626, 2629, 2650, 2668, 2727, 2730, 2775, 3030, 3065, 3068, 3070], [345, 2537, 2384, 487, 1123, 1101, 2271, 2166, 2060, 2578, 573, 302, 759, 710, 2712, 2623, 1076, 448, 855, 591, 1129, 3119, 2416, 2692, 479, 70, 1135, 482, 1563, 2665, 133, 797, 950, 563, 1808, 1919, 511, 773, 1871, 1549, 11, 962, 1336, 73, 2994, 758, 2013, 359, 1545, 1401, 2310, 1435, 1516, 1051, 1863, 1519, 1150, 2984, 2887, 2058, 155, 973, 25, 2008, 1607, 976, 1566, 1857, 72, 2175, 2290, 2915, 1667, 2244, 1226, 835, 2291, 2625, 547, 2272, 75, 2588, 1765, 2613, 968, 2750, 435, 1105, 1013, 2397, 2920, 2907, 2145, 1834, 954, 2978, 297, 1764, 138, 1552, 738, 2826, 278, 1873, 2146, 102, 2001, 1994, 2395, 2615, 317, 303, 1812, 1431, 1314, 204, 821, 175, 2333, 1306, 2952, 2284, 505, 2237, 2365, 2024, 2565, 2415, 2899, 188, 1987, 2799, 1412, 2043, 2874, 402, 2988, 2904, 2168, 232, 498, 1515, 2149, 2173, 2671, 19, 2597, 81, 916, 251, 2788, 2631, 1909, 24, 2591, 2672, 1682, 2521, 2184, 1962, 1903, 2683, 1826, 2647, 2662, 2267, 2407, 2606, 2417, 2369, 2522, 987, 2829, 956, 2294, 2726, 2612, 2288, 2768, 1932, 1558, 496, 2763, 2091, 2073, 2305, 2475, 1342, 2529, 271, 656, 2627, 2245, 2539, 1542, 2540, 1368, 2019, 1814, 285, 2670, 2474, 1778, 2765, 1186, 2567, 348, 1517, 1126, 540, 1730, 2993, 2051, 2261, 1063, 2156, 1762, 1957, 2177, 1530, 1916, 2985, 2155, 1949, 587, 2630, 966, 347, 586, 2621, 1537, 1868, 2669, 116, 657, 1154, 2178, 651, 1786, 245, 2728, 2157, 1937, 2295, 955, 2912, 2810, 2188, 2020, 2766, 2165, 117, 850, 2564, 1939, 2084, 1533, 1771, 1678, 2249, 1691, 1961, 1425, 290, 346, 1910, 1363, 1900, 1329, 1365, 2239, 2179, 2667, 2042, 2585, 1774, 2538, 450, 2243, 2673, 2414, 495, 763, 2154, 2560, 2460, 2760, 2595, 1862, 1116, 2917, 2517, 2468, 88, 2508, 2240, 2076, 2065, 2533, 2278, 1176, 2082, 2421, 2764, 2948, 136, 2622, 1165, 2066, 2957, 108, 2828, 268, 2940, 2402, 929, 2425, 2802, 1951, 2527, 2807, 2666, 2406, 2298, 2791, 172, 2992, 404, 2570, 2946, 2424, 1955, 2476, 3020, 2594, 2478, 2850, 1175, 2589, 1669, 360, 769, 392, 1952, 2247, 2276, 621, 964, 1954, 2571, 344, 2054, 2573, 2142, 512, 2106, 2624, 2078, 2277, 2806, 2616, 2634, 2144, 2252, 1917, 2605, 2511, 1180, 781, 1311, 2080, 1179, 2660, 1183, 2412, 2473, 1420, 1434, 2426, 1127, 2056, 1423, 2470, 1908, 2986, 1174, 765, 2603, 2944, 2918, 659, 1551, 247, 1950, 2593, 1968, 1767, 1959, 2309, 1191, 118, 1182, 2602, 1120, 771, 1190, 2664, 2159, 3074, 2480, 2509, 129, 2871, 965, 1707, 2503, 2483, 2790, 1188, 2518, 2251, 370, 2282, 2160, 2311, 2633, 2956, 160, 2905, 1938, 2280, 1185, 2255, 367, 2254, 772, 1502, 369, 2909, 2805, 2479, 2793, 2312, 2253, 957, 1189, 1422, 2248, 2147, 1737, 32, 2906, 1121, 775, 128, 2081, 2617, 1290, 2989, 2943, 2610, 1520, 2287, 546, 2635, 124, 760, 2077, 2598, 1526, 2063, 774, 2482, 1381, 131, 120, 2809, 2584, 1184, 1964, 364, 132, 2250, 373, 2812, 122, 2064, 2991, 119, 2582, 764, 371, 2607, 1147, 2292, 2911, 375, 2068, 288, 1652, 2614, 2955, 1140, 1138, 114, 497, 1134, 2071, 1969, 1187, 231, 770, 2942, 2510, 762, 1173, 2481, 2945, 2579, 130, 1133, 1128, 2469, 768, 2275, 2958, 2242, 1377, 125, 135, 2069, 1289, 776, 1137, 372, 126, 2950, 376, 767, 1497, 2954, 1159, 2067, 1119, 777, 2590, 361, 230, 366, 2514, 1499, 379, 766, 363, 2581, 2516, 368, 1177, 2953, 2947, 963, 1507, 377, 287, 79, 378, 778, 1511, 1503, 1508, 1498, 2951, 78, 1496, 1504, 1506, 1505, 1118, 1510, 1501, 1513, 365, 1512, 1500, 1178, 1514, 127, 121]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date4.csv\n",
      "created new AL object\n",
      "training on  91  points\n",
      "Learned kernel: RationalQuadratic(alpha=11.4, length_scale=211)\n",
      "total_y:  3122\n",
      "acquisition function with strategy:  greedy\n",
      "training on  665  points\n",
      "Learned kernel: RationalQuadratic(alpha=0.000759, length_scale=11.7)\n",
      "total_y:  3122\n",
      "Strategy: greedy, AUC: 0.6743487088237978, P: 0.2715654952076677, Var: 0.8546794056892395\n",
      "indexes checked by embedding [11, 19, 25, 30, 31, 32, 78, 79, 86, 88, 97, 100, 105, 108, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 138, 160, 172, 185, 204, 216, 217, 223, 224, 230, 231, 232, 238, 239, 247, 251, 261, 271, 278, 285, 286, 287, 288, 290, 292, 297, 302, 318, 328, 330, 333, 335, 344, 346, 347, 348, 350, 357, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 388, 392, 402, 404, 410, 414, 442, 450, 487, 494, 497, 498, 505, 511, 512, 513, 518, 525, 546, 555, 560, 563, 570, 572, 575, 577, 584, 585, 586, 587, 589, 591, 608, 609, 616, 621, 631, 633, 636, 645, 651, 656, 657, 659, 660, 677, 703, 707, 715, 722, 729, 741, 756, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 774, 775, 776, 777, 778, 781, 789, 821, 826, 835, 844, 848, 850, 855, 864, 881, 914, 916, 921, 929, 954, 955, 957, 962, 963, 964, 965, 966, 1013, 1015, 1016, 1050, 1051, 1071, 1090, 1099, 1100, 1101, 1105, 1116, 1118, 1119, 1120, 1121, 1123, 1125, 1126, 1127, 1128, 1131, 1132, 1133, 1134, 1140, 1142, 1147, 1159, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1221, 1228, 1275, 1282, 1289, 1290, 1292, 1306, 1310, 1311, 1314, 1315, 1320, 1321, 1329, 1339, 1363, 1365, 1368, 1371, 1376, 1377, 1378, 1381, 1401, 1411, 1412, 1416, 1420, 1422, 1425, 1434, 1453, 1475, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1510, 1511, 1512, 1513, 1514, 1515, 1517, 1520, 1526, 1529, 1530, 1533, 1542, 1544, 1545, 1550, 1558, 1563, 1652, 1667, 1669, 1678, 1682, 1691, 1698, 1701, 1707, 1713, 1730, 1732, 1737, 1762, 1767, 1778, 1786, 1787, 1789, 1790, 1791, 1794, 1796, 1797, 1798, 1800, 1808, 1812, 1814, 1819, 1821, 1826, 1830, 1832, 1833, 1834, 1835, 1862, 1887, 1888, 1897, 1900, 1908, 1909, 1910, 1919, 1932, 1938, 1940, 1942, 1945, 1946, 1949, 1952, 1956, 1959, 1961, 1962, 1964, 1968, 1969, 1975, 1987, 1994, 2001, 2005, 2009, 2013, 2014, 2018, 2019, 2020, 2024, 2032, 2034, 2040, 2042, 2043, 2047, 2054, 2055, 2056, 2058, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2071, 2075, 2076, 2077, 2078, 2080, 2081, 2084, 2091, 2106, 2118, 2123, 2127, 2138, 2140, 2141, 2142, 2144, 2147, 2149, 2151, 2152, 2154, 2155, 2156, 2157, 2159, 2160, 2165, 2168, 2170, 2173, 2175, 2176, 2177, 2178, 2179, 2184, 2186, 2188, 2190, 2197, 2198, 2222, 2237, 2239, 2240, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2261, 2267, 2272, 2275, 2276, 2279, 2280, 2282, 2284, 2287, 2291, 2292, 2294, 2295, 2298, 2299, 2304, 2305, 2306, 2308, 2309, 2310, 2311, 2312, 2329, 2346, 2355, 2357, 2358, 2362, 2365, 2368, 2369, 2370, 2376, 2378, 2384, 2386, 2398, 2402, 2403, 2406, 2407, 2412, 2414, 2417, 2421, 2424, 2425, 2426, 2450, 2460, 2465, 2466, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2503, 2509, 2510, 2511, 2514, 2516, 2517, 2519, 2522, 2527, 2538, 2539, 2540, 2548, 2559, 2560, 2562, 2565, 2567, 2568, 2570, 2571, 2573, 2574, 2579, 2581, 2582, 2584, 2585, 2588, 2589, 2590, 2593, 2594, 2595, 2598, 2602, 2603, 2605, 2607, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2621, 2622, 2624, 2626, 2627, 2629, 2630, 2631, 2633, 2634, 2635, 2636, 2647, 2650, 2655, 2657, 2660, 2662, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2683, 2727, 2730, 2743, 2750, 2760, 2764, 2765, 2766, 2769, 2775, 2783, 2788, 2790, 2791, 2793, 2799, 2802, 2805, 2807, 2809, 2812, 2821, 2826, 2828, 2837, 2841, 2850, 2871, 2874, 2899, 2905, 2906, 2911, 2917, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2978, 2984, 2985, 2986, 2988, 2989, 2991, 2992, 2993, 2994, 3020, 3030, 3065, 3068, 3070, 3074]\n",
      "hist_indexes [[97, 100, 105, 185, 216, 217, 223, 224, 261, 318, 350, 357, 374, 376, 388, 555, 560, 577, 631, 636, 645, 677, 707, 722, 729, 826, 864, 881, 1221, 1275, 1282, 1339, 1371, 1376, 1411, 1416, 1453, 1544, 1550, 1713, 1732, 1790, 1791, 1794, 1796, 1800, 1812, 1821, 1833, 1835, 1897, 1942, 1945, 1946, 1956, 1975, 2032, 2055, 2061, 2118, 2329, 2346, 2358, 2362, 2378, 2398, 2403, 2450, 2465, 2472, 2477, 2478, 2503, 2509, 2514, 2517, 2519, 2568, 2574, 2611, 2626, 2629, 2650, 2668, 2727, 2730, 2775, 3030, 3065, 3068, 3070], [2141, 1378, 2994, 2123, 703, 2386, 2899, 660, 525, 1563, 1368, 1862, 2005, 2905, 586, 2407, 616, 2047, 1365, 2376, 1887, 2084, 1701, 2589, 914, 11, 2197, 414, 563, 1762, 2222, 2370, 2466, 966, 2788, 1517, 1830, 2140, 1940, 715, 921, 1558, 402, 1125, 2821, 2009, 2355, 1090, 1142, 2603, 954, 2565, 2765, 278, 297, 585, 1682, 238, 2384, 2631, 2540, 2582, 2279, 2985, 2062, 1819, 2018, 2365, 2091, 2176, 1320, 2850, 916, 1127, 2138, 2261, 31, 789, 108, 2190, 2291, 2421, 2538, 2769, 118, 2013, 2001, 2417, 204, 1228, 608, 821, 2299, 2957, 835, 651, 2040, 1051, 591, 1105, 2065, 2993, 589, 1101, 1667, 1529, 2034, 2256, 633, 2667, 442, 2170, 1071, 2267, 855, 513, 1310, 2636, 2306, 86, 656, 2127, 2766, 1908, 330, 844, 286, 962, 2841, 2075, 1669, 2425, 511, 2562, 1119, 2588, 2308, 2621, 609, 1329, 2151, 964, 2657, 335, 2173, 2460, 2368, 160, 2662, 2471, 2198, 2612, 1834, 2665, 2743, 2672, 498, 1778, 172, 587, 2424, 2655, 2522, 2837, 302, 2475, 2559, 2043, 2760, 2594, 2764, 3074, 333, 1787, 2304, 572, 3020, 2357, 1533, 741, 1832, 2244, 1292, 2750, 290, 348, 1994, 133, 2239, 19, 2941, 1932, 1542, 1321, 2952, 1691, 2548, 2809, 1789, 1910, 2014, 2791, 271, 2152, 1422, 1016, 2406, 344, 2567, 117, 285, 2585, 30, 1123, 756, 2615, 1678, 2911, 2511, 1131, 2978, 2510, 1798, 2186, 1159, 2243, 2539, 2595, 1176, 2054, 1315, 1015, 1314, 2276, 1126, 2647, 123, 138, 2906, 2295, 2673, 2593, 450, 1420, 347, 1425, 2683, 292, 2066, 2630, 2272, 2917, 360, 659, 1900, 1186, 251, 2799, 2402, 2946, 1050, 2175, 763, 1099, 410, 2414, 505, 2805, 2874, 2280, 346, 2802, 2986, 2310, 1888, 1961, 2305, 2168, 1808, 2058, 25, 2613, 1949, 2284, 955, 2783, 1909, 570, 487, 965, 2664, 1987, 2042, 1401, 2984, 1013, 2634, 2024, 1797, 2106, 2988, 88, 2155, 1962, 1434, 2660, 929, 1475, 131, 2063, 116, 1698, 2570, 1952, 2369, 2056, 239, 494, 2669, 2622, 2177, 1826, 2826, 2412, 575, 2184, 2149, 1767, 2178, 2237, 2468, 328, 781, 1814, 1100, 1179, 657, 2019, 1191, 231, 288, 2948, 2790, 128, 2807, 1530, 1290, 621, 2616, 1190, 2246, 2560, 2476, 1968, 848, 2670, 2248, 247, 2573, 2671, 2989, 1363, 2426, 2240, 120, 2157, 2165, 2179, 2944, 2245, 2154, 2249, 1182, 2080, 1545, 1116, 2474, 2254, 404, 2076, 1730, 1938, 1134, 765, 2992, 2159, 1132, 2078, 1133, 2251, 512, 2828, 1120, 1175, 2144, 232, 2956, 2635, 2156, 2294, 2142, 2581, 850, 1412, 2627, 2624, 2309, 129, 1381, 1919, 2188, 1497, 546, 2516, 2527, 2940, 132, 2605, 2812, 2077, 2470, 584, 1121, 2064, 1707, 1515, 1180, 1737, 1502, 2666, 1140, 2479, 2252, 1183, 2071, 2255, 2160, 2247, 1289, 367, 392, 2298, 2069, 771, 2480, 1959, 2068, 2943, 2287, 2311, 2483, 518, 364, 957, 1499, 769, 124, 2602, 1964, 2571, 2871, 764, 1306, 1184, 2312, 122, 2275, 2081, 1118, 762, 2147, 2020, 2793, 135, 777, 2482, 125, 32, 2610, 230, 2590, 2633, 772, 1147, 2250, 2598, 768, 2991, 2584, 2473, 1188, 119, 1652, 1185, 114, 79, 130, 1520, 2958, 370, 2282, 2253, 2579, 2242, 2945, 770, 774, 1498, 2614, 1189, 760, 373, 2607, 1377, 2067, 1174, 2617, 1786, 2954, 2481, 287, 1526, 378, 2469, 766, 767, 775, 497, 1969, 379, 375, 778, 2292, 1173, 2953, 776, 1507, 1311, 372, 1128, 2947, 963, 78, 126, 369, 371, 2942, 1187, 363, 2955, 1177, 2950, 368, 1504, 1508, 1503, 366, 1505, 1506, 361, 1513, 2951, 1496, 1511, 377, 1500, 1510, 1501, 365, 1514, 1512, 127, 1178, 121]]\n",
      "List of lists saved as CSV to ../script_results/1_batch_real_direct_esm3_coord/training_indices_history_bloom_1000_date5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get end dates from detailed_results_df\n",
    "end_dates = detailed_results_df['end_date'].values\n",
    "\n",
    "# Prepare a list to hold all rows for the final dataframe\n",
    "results = []\n",
    "\n",
    "# Define biomodel and strategy\n",
    "biomodel = 'direct'\n",
    "strategy = 'greedy'\n",
    "\n",
    "# Loop through mutation indexes and process results\n",
    "for date_index, indexes in enumerate(mutation_indexes_results):\n",
    "    NB_0 = len(indexes)  # Initial number of points\n",
    "    NB_POINTS = 500 + 165 - NB_0  # Total points to use\n",
    "    NB_ROUNDS = 1  # Only one round\n",
    "\n",
    "    # Prepare initial training data\n",
    "    train_0_indexes = indexes\n",
    "    train_0_x = torch.stack([dataset.data_x[i] for i in train_0_indexes])\n",
    "    train_0_y = torch.stack([dataset.data_y[i] for i in train_0_indexes])\n",
    "    dataset_0 = Dataset_perso(train_0_x, train_0_y)\n",
    "\n",
    "    # Run the active learner and collect r2, p, and var\n",
    "    r2_list, p_list, var_list, active_learner = run_active_learner(\n",
    "        strategy=strategy,\n",
    "        dataset_0=dataset_0,\n",
    "        dataset=dataset,\n",
    "        NB_POINTS=NB_POINTS,\n",
    "        NB_ROUNDS=NB_ROUNDS,\n",
    "        biomodel=biomodel,\n",
    "    )\n",
    "\n",
    "    # Collect results for the single round (end of round 1)\n",
    "    results.append({\n",
    "        \"end_dates\": end_dates[date_index],\n",
    "        \"indexes\": indexes,\n",
    "        \"p\": p_list[-1],   # Last value of p (end of round 1)\n",
    "        \"r2\": r2_list[-1], # Last value of r2 (end of round 1)\n",
    "        \"var\": var_list[-1] # Last value of var (end of round 1)\n",
    "    })\n",
    "\n",
    "    save_indexes(active_learner, date_index)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Convert the results list into a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    end_dates         p        r2       var  \\\n",
      "0  2020-06-30  0.332268  0.776944  1.183034   \n",
      "1  2020-12-31  0.166134  0.589052  0.532625   \n",
      "2  2021-06-30  0.172524  0.595655  0.567628   \n",
      "3  2021-12-31  0.255591  0.693265  1.009955   \n",
      "4  2022-06-30  0.271565  0.705568  0.839319   \n",
      "5  2022-12-31  0.271565  0.674349  0.854679   \n",
      "\n",
      "                                             indexes  \n",
      "0                                  [3030, 1956, 555]  \n",
      "1  [1411, 2362, 1956, 1732, 555, 1713, 1946, 2730...  \n",
      "2  [1956, 1946, 2730, 223, 1945, 2629, 2378, 1544...  \n",
      "3  [826, 185, 1956, 97, 1376, 881, 318, 1946, 145...  \n",
      "4  [1221, 881, 677, 2568, 636, 261, 2519, 645, 12...  \n",
      "5  [1221, 2478, 881, 677, 1796, 2568, 636, 261, 2...  \n"
     ]
    }
   ],
   "source": [
    "results_df = results_df[[\"end_dates\", \"p\", \"r2\", \"var\", \"indexes\"]]\n",
    "\n",
    "# Display or save the dataframe\n",
    "print(results_df)\n",
    "results_df.to_csv(\"../script_results/1_batch_real_direct_esm3_coord/bloom_1_batch_real_1000.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     end_dates         p        r2       var  \\\n",
    "# 0  2020-06-30  0.335463  0.781978  1.182352   \n",
    "# 1  2020-12-31  0.175719  0.593399  0.533985   \n",
    "# 2  2021-06-30  0.175719  0.600066  0.568055   \n",
    "# 3  2021-12-31  0.258786  0.699422  1.007511   \n",
    "# 4  2022-06-30  0.271565  0.706349  0.836747   \n",
    "# 5  2022-12-31  0.277955  0.680278  0.854968 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
